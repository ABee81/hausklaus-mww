{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8fc0db",
   "metadata": {},
   "source": [
    "# HausKlaus microWakeWord\n",
    "This notebook is based on basic_training_notebook.ipynb from microWakeWord from here: https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb.\n",
    "\n",
    "Datasets were extended, configured properly for mls model and training parameters were changed for longer training.\n",
    "Executing this notebook step by step will create a stream_state_internal_quant.tflite file in data/trained_models/hausklaus/tflite_stream_state_internal_quant.\n",
    "This model can then be used in esphome on the HA VPE for an on device wakeword detection.\n",
    "\n",
    "A model pretrained for the wakeword \"hausklaus\" can be found in model/ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d11a33",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38bfcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/adeemb/HausKlaus/hausklaus-mww/microWakeWord\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: audiomentations in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (0.41.0)\n",
      "Requirement already satisfied: audio_metadata in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (0.11.1)\n",
      "Requirement already satisfied: datasets in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: mmap_ninja in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (0.7.4)\n",
      "Requirement already satisfied: numpy in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: pymicro-features in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: tensorflow>=2.16 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: webrtcvad in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from microwakeword==0.1.0) (2.0.10)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorflow>=2.16->microwakeword==0.1.0) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16->microwakeword==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16->microwakeword==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16->microwakeword==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16->microwakeword==0.1.0) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.16->microwakeword==0.1.0) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.16->microwakeword==0.1.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.16->microwakeword==0.1.0) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.16->microwakeword==0.1.0) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (14.0.0)\n",
      "Requirement already satisfied: namex in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.16->microwakeword==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: attrs<19.4,>=18.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (19.3.0)\n",
      "Requirement already satisfied: bidict<1.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (0.23.1)\n",
      "Requirement already satisfied: bitstruct<9.0,>=6.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (8.21.0)\n",
      "Requirement already satisfied: more-itertools<9.0,>=4.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (8.14.0)\n",
      "Requirement already satisfied: pendulum!=2.0.5,!=2.1.0,<=3.0,>=2.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pprintpp<1.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: tbm-utils<3.0,>=2.3 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audio_metadata->microwakeword==0.1.0) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from pendulum!=2.0.5,!=2.1.0,<=3.0,>=2.0->audio_metadata->microwakeword==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2020.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from pendulum!=2.0.5,!=2.1.0,<=3.0,>=2.0->audio_metadata->microwakeword==0.1.0) (2025.2)\n",
      "Requirement already satisfied: time-machine>=2.6.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from pendulum!=2.0.5,!=2.1.0,<=3.0,>=2.0->audio_metadata->microwakeword==0.1.0) (2.16.0)\n",
      "Requirement already satisfied: numpy-minmax<1,>=0.3.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: numpy-rms<1,>=0.4.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (0.5.0)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (0.10.2.post1)\n",
      "Requirement already satisfied: python-stretch<1,>=0.3.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: scipy<2,>=1.4 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (1.15.3)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from audiomentations->microwakeword==0.1.0) (0.5.0.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (5.2.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (0.61.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (1.8.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from numpy-minmax<1,>=0.3.0->audiomentations->microwakeword==0.1.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations->microwakeword==0.1.0) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (4.3.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations->microwakeword==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from datasets->microwakeword==0.1.0) (0.32.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (3.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->microwakeword==0.1.0) (1.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets->microwakeword==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from pandas->datasets->microwakeword==0.1.0) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.16->microwakeword==0.1.0) (0.1.2)\n",
      "Building wheels for collected packages: microwakeword\n",
      "  Building editable for microwakeword (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for microwakeword: filename=microwakeword-0.1.0-0.editable-py3-none-any.whl size=9919 sha256=dbfe94c5b0d4da03c8f2c07670593a812b9a3738c9a03c963a1326d1dc098e14\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ui38jnev/wheels/f3/cb/76/6a1c73fabb57d6ca38ed0550a86dce943136b793fef2b11989\n",
      "Successfully built microwakeword\n",
      "Installing collected packages: microwakeword\n",
      "  Attempting uninstall: microwakeword\n",
      "    Found existing installation: microwakeword 0.1.0\n",
      "    Uninstalling microwakeword-0.1.0:\n",
      "      Successfully uninstalled microwakeword-0.1.0\n",
      "Successfully installed microwakeword-0.1.0\n",
      "--2025-05-29 19:58:36--  https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/de_DE-mls-medium.pt\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/642029941/4dc5c648-f4ad-40aa-99d0-937aeece3287?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250529%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250529T175836Z&X-Amz-Expires=300&X-Amz-Signature=9fb7400dff948abc742da72a1f314b402c66b1dbb7263c19f8cf9f1c2d2dd2d5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dde_DE-mls-medium.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-05-29 19:58:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/642029941/4dc5c648-f4ad-40aa-99d0-937aeece3287?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250529%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250529T175836Z&X-Amz-Expires=300&X-Amz-Signature=9fb7400dff948abc742da72a1f314b402c66b1dbb7263c19f8cf9f1c2d2dd2d5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dde_DE-mls-medium.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 202679851 (193M) [application/octet-stream]\n",
      "Saving to: ‘piper-sample-generator/models/de_DE-mls-medium.pt’\n",
      "\n",
      "piper-sample-genera 100%[===================>] 193.29M  31.5MB/s    in 6.2s    \n",
      "\n",
      "2025-05-29 19:58:43 (31.3 MB/s) - ‘piper-sample-generator/models/de_DE-mls-medium.pt’ saved [202679851/202679851]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install microWakeWord\n",
    "!pip install -e ./microWakeWord\n",
    "\n",
    "# Download mls model for de_DE\n",
    "!wget -O piper-sample-generator/models/de_DE-mls-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/de_DE-mls-medium.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5142a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python310.zip',\n",
       " '/usr/lib/python3.10',\n",
       " '/usr/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/adeemb/HausKlaus/.venv/lib/python3.10/site-packages',\n",
       " './piper-sample-generator/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./piper-sample-generator/\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41cc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.7.0 available.\n",
      "INFO:datasets:TensorFlow version 2.19.0 available.\n"
     ]
    }
   ],
   "source": [
    "from generate_samples import generate_samples\n",
    "from IPython.display import Audio\n",
    "import datasets\n",
    "import scipy\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936d0d2",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAKEWORD = \"hausklaus,\"\n",
    "SAMPLE_COUNT = 4096\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dfa31",
   "metadata": {},
   "source": [
    "## Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76429a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Loading piper-sample-generator/models/de_DE-mls-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Phonemes: ['h', 'ˈ', 'a', 'ʊ', 's', 'k', 'l', 'ˌ', 'a', 'ʊ', 's', ',', ' ']\n",
      "DEBUG:generate_samples:Batch 1/0 complete\n",
      "INFO:generate_samples:Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/x-wav;base64,UklGRgSxAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YeCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//wEA/v8CAP3/AwD9/wQA/P8EAPz/BAD9/wIAAAD7/xQAVP9x/nz+wf5k/lD/FP/P/tn/Qf91/pv+S/4j/pr/yP5F/jP/a/55/uP+F//n/vv+fP9J/mH+Nv9W/sr+Gf+J/qT+2f7I/s79K/4f/hf+R//+/lX+1v4t/tb9Wv9k/gT/M/8Z/sX+yf7h/nf+xv52/vX9l/6a/tT+rf6Q/nD+5P1e/i3/vP7f/g//yf1//p7+Xf73/r7+vv5n/qn+mv7P/SD+Xv78/SP/X//A/u3+i/7i/af9jf4g/s79gf7z/ab+Cf96/o/+N/4P/qD+Cv8M/6z+L/4r/sH98v0l/jT+b/7P/t/+sv4p/6v+R/4y/sf98v0D/i3+8v4L/6P+N/5O/k/+bP7I/p/+Z/62/on+Jv5U/mX+P/44/kv+iP5S/0f+Uf42/pP95/7Y/l/+mv7u/Sv+hP5H/g//Fv73/fj9cP0G/qD+kP7j/in/lv5F/0b/EP/H/gT+n/2B/S3+9/66/ykAI/8P/xv+nP2J/jn+b/7Y/Rr+XP5I/1MAlf8o/0r+UP7U/v79B/48/uj9rf4T/3b/mv+C/7T+N/6w/r7+X/5e/lb+Wf0b/3T/Hv/A/57+Wv6//Zb+4v6M/kn/KP8S/0//Jf+h/kX+A/7K/pr+Q/9b/03+sP7h/RD+kv7F/pT/uP/M/6r/VP+u/vP8B/1D/iL/3f9s/gf+V//c/wkAkAB+/3r+4P5k/q7+JP8G/0b+sf7M/yD/yv/j/+T+Iv9g/zT/g/97/4/+Qv5M/k3/GADT/1//9/9jADr/Nv8O/9v9lP6+/gT/qgBbAGEAWgAS/7f+9v6x/uj/Qv8U/lv+Yf5zAIQA5wCGAB7/q/5w/Yj+tf6Y/kz/1/5WAMkAMv+9/+n+V/4B/2/+rv/S/2T/+v55/qj/c/97/yT/mf5+/9f/JACb/0X+0v38/bn+FwBTANj/CwDh//n/qf///jv/J/5V/Q/+5f4pACUBawFZAB7/1/6r/W39t/2P/WT+cv/eAMgAvwBNAJ7+Av+p/hP+pP5m/7b/Kf/P/2AA3f76/fb91/xU/mj/LP6W/3L/Wf5R/2b/+/7d/mD/+P6+/d/+8v6N/uf/LP+p/p3+M/75/Uv+mf5r/kf/1f45/p3+3/5I/nb+9f5J/9D/cP91AML/pP71/aL8hv2a/RP+eP81AGUAPf8a/+b+1v28/tn+9v0I/wr+bv1n/0j/gP8tADX/X/5X/sn+0f2//bX+Ov4f/5f/FP83//L+8P2C/Qz+vv5v/iX+D/9S//b+xf7Z/j/+W/7o/tn+2v4I/03+Df6k/hz+cv77/jn+Ff5u/vX+oAAXAHr+1v3N/On8Pf6c/sj/LQHx/1H+rf2K/cD9zv6+/rj+pP95/33/zP7x/MD72fvh/YUAXwKmAUr/pf6B/Vz8p/2x/W79FP9n/7EAXwF1AMj+0/wz/Uf9pP34/n3/qP8nAD0ASwFaATAA+v71/ML7ufrK+2z/NgJ5AxgCcv+3/qr98f25//b/uv3W/Or9/v09AboCcQG9ADn/Lf5G/Rz9tf4aABkA+v9Y/08ACAHy/xX/4v1r/Rj+c/+gABcAvQBdAYL/c/98/n79Vv1D/b/+pv8HAXgB3gH9Aff/1f6S/Nv6gf12/zYABQLmASEAjv94/hL+WP7X/Xv+t//hAVQCOABW/kD94/2mAHQBjf49/Cb9xf/YAK8CTAMeAJv+8/14/e//tgJpAdz9Xf0I/f78Mv/z/08A0ADaAOcAOQIRAuT+sfsE+6D7kvxVAGUDMgVFBC7/pvwp/cP8pv0A/xkAsgBqATABCv/9/mL96vwJ/20AowB0ACsA3f9O/yn/j/+s/XP9U/63/m3/4ADkAPn/8wB6ANL9gf3A/DX8xf8JAJEBQQTAAwYCDf0H+V33XPhV/GMBaAZJBrMDaQA1/N77kvrL+vr90P5j/4T/eACjAksDsgLoAV7/vPtQ+dn3cvms/jkDMQOVAX4BEACG/pn9N/sC+4v8R/78ALgALAAkAOoAqAJ5AEj+Hf37/cH+mv2K/yP9a/p//Y7+Af/f/7v+QP3u/4oCcgH/ACr+0Puv/YX+FP6d/6L/+P0l/3P+3P1r/zb/NgCgAvoB6v1V/Ij9Wv4hAIH/Qfxf/Ej9P/zk/hACXAGnAtABUf+H/jT85/hn+dr9of+wAQMDiAH5/5b+g/1P/+sADACt/Kz4UPqq/YH/6/5n/6wBtQLFAVYASQC2/+D9Rf1w/wj/p/zg+Xr4e/um/goBFwR+BlkDY/vz+Qb9Kf9EAe8A4QANAYH+r/pk+tz7SPwh/8IBhwOIBSwEkgD0/Ur6nfa790H7PQA1BBgEpwOlA5sA7fn/+LH7k/u5/A//KwLTBb4FpACL/Gb6zPq0/Pz9Mv6Z/UkAVwAGABIDagKxAYgBt/8U/qj7u/g1+HT6Bv5hA/EH3QaoAW3+3/vZ/DUAwf7C/B389PyT/Ub9p/8dApgDAQTnAJb8zfl1+2z/6QDr/g/9LP9nAIEA5AC1AVsDLARrAqf82Pdm9n/4fv22AVoERQU4BH7/m/tg/WL+Zv75/g390P5TARUBrwF6AK//mv50/57/hv3t/Iz8Pf4BAb0DwgB//TP9Dfuz/bQCkgOgAw4CQP5x/KT6x/nC/AkBSQRpBscFMAOS/8f58vU99ov28PnFAOkElwftBjQFMgXrAdb9aPvX9wb1FvdG+63+XAOLBmQHbQY2BG4B/P1H+zL2Gfa4/Lv9Tv0XAYcDqwKl/7//qP+a/gwAm/8H/5P/7P9i/HP7Kf/HAKn+h/yf/f39wAFRBGkBOf6l/Br69Pnk/Wn/ZgE+A0YBxf/jApX/Gvmf+r/8nP6CADP/6/9q/xj8BAFtBbIBdP30+lb4xPrA/dv91wEtBBEE3QJ1/+r76/sN++H4gPob/1IDqQJWA14DKQAa/JX44fsM/139Evyz/qf/6fyn/DD/oAQ0CHoGiwHa+4z2aPYm+pX+tgJqAgcCqACp/VT+FQH6/hf8d/zd/VP/igLiBZYDWwDa+6r4S/oV/Er+HwAKAKYAHANXBeUB2vtV+V/6S//QAQQA4Pyk+nX64fyEAUwGawb/AkwCNQDz+yn4B/UB9Wn6e/8dBPIKDQsbAx/9Tv3m/NP5svWb9Sz7+f/8AJgDNQn1CPMG9wXp+07yX/FY8B738gKvBiQEjwD/AM0F2whtBer+g/nF9xf5cfpG/MP+9//qAF4DqAMfABn+Q//OAeQClAC5/dn87vxz/Mn5P/tD/7cAEgKcAREELQTM/mv8dv3i/fIBawJM/7X8vvXv9/78m/5pAJ4CEgYpCdIHBwL//DL7D/qY+D/7T/kn+g3/3gFIBlkHvgSDAKP9YPyn++P8BwAhAVkBEP+h/BX+E//5/yT+0f+MBXYDOvy9+b791gDPA1cD8v0P+xD3IfWl+loANgbcC1YLmgYk/Tv3Jfes99j5aPwn/ykAQQH0Ai0DhQFvAIf8D/q9+7z69vwjAJX/uv0D/j8CmwNDAW3/V/23/Cj/sQHd/+T+CAIjAMr86/z5+Lf2Nft5/OH+IARmBDYFGQb/AnkA1vzH+a77pfxa/Mj78/qO/eP/TgGOApYBCQC4/l4AEwSBAfT6Wfkp+Wv7BADYAc8BCAMuArMApAMH/gL5wPlU+OP6l/79AyEIywS8/lL7qPxW/lb9Pv10/Iv80/sl+eP5If+OBdcJfAo9CM8BR/h/8+/x4PR693b80APtBCMFUgEQ/YP+hABE/k79bPyg+Fn4J/vW/TMDsQW3AckAdP8R+o74DfsS+0v7TPxL/Mz9vACSAZUBpAHsASwAmfqn9t/1ffnj/n4D/QJtApYEpgNRAhkBA/3s+DT6Xvtr/Mr9F/qb9tH4/Px8/2ICFgZ2A9r+Df4P/N/6nvzV/rX/0f98/5j/+f60/qD7y/aa9pv2W/nb/p0BIwRBB4YH3wZcA2b7pPVQ8vr1XP14//cAFwFM/1z/DAE6AmsB0/1K+Cf1ivWx+Gf9BgEbBl8K0QmeBxkCZfot9Mvye/Zk+8P/HgLuAuwC/ALFAf//2/1w+oL4xPhJ+zn/ggEPAh0CCwPtA5kA0fvi9gfz1/VL/G8ANAReBfcBdgH9AEz9Y/vl+0/8Bf4pApMBzf1C/Wb8+/9zBF8AWPsP+hX5OvkB/o8BZwEUAMD+bv4c/3v/mgCEAn8CnwHj/4v9vvoc+kv7jf56AT8AIQJ/BJkCYAI6AJr8wftX+hP60/mi97b5wf5iAk8HhgjLBAX/D/q1+Kv5Vvn39y/7IP8A/3/9lP1v/Kn7sfzX+mn5sPt8+1P7cv7a/2D//f6E/if98/6YAEv/zP/DASMAVv1B+6D4gvg4+1AAnALOBRUGVv5R+5X6VPdW+UT+YAG5BfYIXgeTBEAE5gHQ/DP6Mvl/+DX72v0e/+ECFgVNA/wE6AfZBHQCkQA8/Fz6p/tr/G/+TwAcAOsBXwN2AesAzv/V+2v9ev7+/YwBzQGd/eL5xPfa+Bn+oAS/CKoI9QUg/gj44vaX8r/wifIi89D1q/nl/LQABwEYAJAA7f7e/Bz6PPVZ8CTzt/fB89TyJ/Zr+Qz/RgKMAA4AnP4k91L0QPVa9Tn4c/xA/ur+xgGRAAz99P18ASkEywWECJoI0gZUB30FjQJIAVz+EPw+/cX+Pf/YAXoDhAMDB8EIHwiiCVkJ/gbXBK0B+/0S/Sr+c/+EAjUELAO0AtYCnwKuAakB7wG8AUUBdP6C/G78ffuc+gX8wf3b/Zr7J/hk9374s/mm/Kn/mf3F+yH7zviH+Kr3P/ZO+MT4a/Yk9XDzCPOl9cr3zvJ07bzrmuTg43ntM/Sb+Q/7ZPnc+jr97P5VANkDyghaEnkfqyixKoEiOBJmAvjuR9vn1OjSftYY5SPzbwEvE6QfdiWQJ/gjlRoiEWAIIP0A95P0LfE78nvztfVQ+0D/UwMIBe8DwAJRAFD+RP5u/oH+k/6l/en+bgKjBfoISg28D88NcQptBygE2wNoBWkDqwDW/rz8lPzo/y8DBgT3A7oDSQINAOf9H/rl9xP4KPfq9P/1jPc29RL3OvzK/cb9Mf34+ED2VvZV84PvUutv5ZLh7N0k3FXg9eQv67bxvvao/6gG/AskFZAeaykCNx8/VTq9L8gdaf+44/fPJMCnuxnCWsrD2/bytQVyG7It+TQ9OYw1qyYeGCQH2fRX7FXntON36IHuSvM6/HQEiAh/C4oKlQS9/xf5GfIE8IbvLvHm9gz/TQllFMkbCiDjIQcfRBhsEYYJwQGq/jL8hvlk+d34Mfkb/t8A4AIxBlwGOAbfBSkDt/6f+s/2zPNQ84zzdvOj9gP7IwCeBdsGuQVcATn5DfSp7RPjVN4H3NzaPt3F3o7fYeRT67jvi/iyAGYAhgUDEaQZUi/aR1dN7k3GQTof5/yb3kvB97Lerxaxdby1zdrhw/zpFocrHjySQSo88jCkHskKcPzk8Lrp3eei5jLoPu+995f/8wZsCKcE5//P99ftMOcM5PTj5+i58Qz88gh8Fg0jwCxDMOwuHCmQIP4YyBBnBrn+GvaT7GDpZuhR6W7vcPfW/v4Fvwx3ECgQTw6pCe0Div40+WP39vaa9cz16PU29/H6evx+/M/6uPYy8DzoXONj4Afdvdto3BDgNeOV5v3sm/BO9Gb3VvjaANkPdiGHQfNblWBUW/BBixmA9GTRdrPAptGgP6FpsZzGMeHYAuUeljS5RfRI+EF/NZUijg6I/8Lz5eo45gPl1Olu8ZX5TwLrB38IIAax/sP07+tN42rd8d175EDtE/xGDuoe9S2yNss3cTRULf0kIRytEN0ERvnr753p3uUv5vTqQvFm9/n+ygbyC+8PaxRRFAYRVQ0ZB8v/Wfmz8t3ubO4M7tbwhfR69pH3Cfi580Dsaenh5m/iUOBn3efaId7O3nvhCud46sTxOPnMBg8ZBi77Tnlncmk2X0RECxq88LXOirHCn3Oaf52nrcPGu+XKBl0kwjxDSl1LmkSrNdQgUQ2d/cTwLueI41XlAu359iIBaQpeDpQNBweV+yzv1uE113XTVdRz2tDli/beCwch1THaO0s/OTz/NQovTCQMF8QIYvnw7Evjw9273sPjYuqb8kX8yQRLC6sQ6xSCFBcSgw6IBywCa/xm9Vjxz+/p8UP36/ry/IH+9fsu9oXwzenI4v7ef9zU2HHW+NWA1VHa8+Ka6Q32iABICOcaSSsiP5Fe12e4XDpMFiVq+D/YQbpcpi+hl6Heq8DB7Nuz+R4Z5DLrQ6VLu0hwO1QnhhS4BNf3oPCL6Rbml+rW7sL0aP1rAjUDDwLQ/ILzI+s04gDcA9zI3cbk6PFXAEUSkSQAMa45XT3hOTg1gy6kH6cOm//G7Rzg5Nqp2M3dc+Wd7Hn5NQNyCAAQDBWqFUAVVhE9C4UF1P5c9//xx/Ct8C3ysvbM+8H/g//S/Lj6g/NL67Tli90+1nTSjNCUz17UD9wB5hz20f/EBf8TkSBfK8VIU2EcXhNYdUAmEjbwyNAnszSsaKb3o620rMSv2i/7GxbpLfo/VUM5Pgk0RSJtEyAI5Pu78zru++tb73HzwvhS/xICmAEm/sz2B+2I5PTdntk82g/fKucH9VkG3xjKKTU1MD2+PhU7UDbULZkgOBF4ATDznOZe3vfbONz84HrpA/Oz/LYFVwzEEYoV2RQfExwReAuOBBL/rPnO9br0WPT/9Iz3Hvkv+sL4dPKF7cLnGt9n3EzYdNLp1FnWPddL3mLmq+1o+UkDMAtdHZYvh0VCYMtiCFdfQwMbGfV51na6CawPpaOj/K6Xwf7XF/VsEzwswD3+RMRBiDf6JgYYzwxaAkP6mPL77nzwDvML99n7FP/X/3L8nPZX7q3k/t1T213cOd+i5u3yRQHQEu0jwS/ENyk8pDzpO+Y4TS7kHTQMLPlI6FjdcNew1j3ayt+e6tT22f9JCu0SrxVGF/wVfRHSDYII5AGF/Hz6UPoZ+g/8OwBRAUj+nfm48y/qod4v1R7Mb8XRxAHLI9A22ujlsOtP+JMChghOEa4cUiYCOKtT0VhAVApKHSdBCnPtcMzGv+KxzKfHsHe5/sYn4aL5Dg+vJGExuTOsM5AtlSN7HaETQwjx/oL2xvPk88715Pl1/OL7Vfj19LXuZ+dc5J3eb9v43frfNeey8wIDixO1IGEsTjSLOAE8Fj3dOM0s5x3FDL75Xuv44SbaRdjW22ngh+nO8zj7iAMnC1MNlg0oDF0IvQRuARX/Af8MAOoAJQRTB2QHVAYsAYT24ewK4OzQxsjCw8PAC8bMzXHSiNwu6cvxwP6dC40RPR5qK+U6alDOVr9SfUVqKe0KOO7T1APEmLjAsg20gryPycDaO/LACAQbZilYMK8uMCmqIQgZHhIfC6YBkPxM+i74BPpV+2n9J/9b+zP2vPHK6KrhBd5N2kPZCN185Oburv2tDKIa2CauMWE5qj4zQVw+9zXtJ1EXtwWj9N7n199I2i/ZTNzA4tDocPHf/OgD8gmJDo0PqA+XDRsKJgb5AiEDnQLHAxMG+gRbAYf71PIy6UvfpdTsy17GP8OwxNPJc9H53w7qk/WhA4cHixH9H5koFjxVUFRRdE3eQcEmQQ6z+lXgcdJGx3W4U7wLwBDHwdtM71sB9BN6HiYi/iR2I/8dlBxhFsgL5wZS/qL5NvrT+uH+OgIHBPECUgCz+7X0qO8O6H7gSt5J3L/eK+eP8eP9kQu3GagmIzG4Ot5BBEC/OfQuGB8wD4n/D/R66aPiKuIy4njmfe2b84r7CQOUB8gIbgh0BjIAlvop+FL2XPcb/O0AzgRZCFwKOAmYBHn6Re6q4fPSy8jZwWfAzced0Hnb1OjY8tL6VQkRF8ogMzflSDxLaE6oQmQtoB7+B8f0Xems07vIQ8gww97L1dq+5r/1oAOLC0sRUxWvFMwUlRQsEJ8LjQcfA/4BHwMABdUHoQoxCx4KlgbI/wz5N/BM5pnfodnf1ira5d/I6k32BQMpEVUddSrgMxA9FEAtO6Q0+SepGb0M6QBz9oXuPOrQ5rXmpejG6tXwBffO+hH+pP9o/u78Svvf+Ij3Q/gw/EsAmQPBBgsJ0geFA0sAPviQ7aHk7djXz/nM+svOzqHVUNuL4mfrLPIM++MJLBWnJ9s+h0NRSL5DtDGjJKMS9QEv8jziItb1zfHLC80J1rDhXu2P+kADegwzEGoQxxK/DxANRQlrBFsC1QAgAYYEHQhbCc4Lhwv8Bk8FfAAx+EP0PezA5LLhdN6Y4JfmY+5l9zACIQ55GncnNzI2OaU6qjbTLqwj6BfwDMUCU/p28zvvBe1h7DHuOfA588/3Ifp1+q36vvcb83zv3+327jjxNvbr/O8CwwVZB3UITATa/ff2c+xM4PTXTtPzz8TUjNo54ZHr5u0I9XH//wpEGVottj2GPdw/8jRNI3gacApB/lnz5uLx263X69Qc267is+tJ9Fv8zQE8BH8FjgSsBvgG0AQmBAIBYQBPAZMDFQlbDFcR5REVEIwOnweQAtX6XfKA7M/kF+Fb4JjhOed+7bX1YwHmDFEYOyVWLowyXzR8MWErgyN/G70SiwmKApP8VPhr9UnzbfHB8K3xJ/HJ8RnzcvFi73XuOe0u7evvTPQE+Y/+VwVBCdkJwAVn/uL4OPD35tzg99mc1ovZi90o5NnsR/E79Yv75wMhDNcccjCINsc7qTd5KZYd/w4rA833/+ul4kbdxtsS3crkNes58cn5Af3p/2UCzP9O//EAx/7y/DH+0P3U/8MFZwi5DYsToBPVFAYTxw3XCH8BWPgp8U/rZuUV42Xk3OZs7IfzmvnWAwgO/RbyIbcpjiuMKlEnoyB7GkAV1w4/CRwF7f/9/Kz6+fcv+DH3fvQy9Prx3e6C7aXqpeh859rpz+yJ8KX2WPwcAfEBFgE4/3r4p/Et7FrlwN+p3VPfFuD05hTr7u7Y98D3df8VCJELRR4/LUAxDDXFLXYiaBf1DAMCefYV7xXlgOIp44fijelg7iHypfcJ+oP7Tvko93v35/aY96r4u/oz/cX/HAUJCmYO1xMNFCcTMhJwDFgGef/e+HjyYe0n6Z7mZuoC7lLz1fkT/3YHSQ4qFZoc+h/7H7oeZhv/Fx0V+xGbEPcM4wrTCLUFiAOh/+D8I/ge9Jvw3etK6fjkCeHx39HgnePl5y3ubPTU+h4AtwOnBCMA3/oG9n3uR+uE6hvmvOmk6xDsLPOa9N34ivw/A7kIog1RIdgoPC2UL2wjBBwYEB0E8/ub7wHoZ+Pc4nPk2+jp77HyFPg0/Hr9Rv4U/Df7zPm2+FP5dPjG+o39bwDlB3AM8BAkFKcTEhQFEPULUgZc/n/4IvH87CXqHupc7nbxevbs/JMCsAj+DzIXCxwSHu4cuRihFXoTmRBhD+sNyQypDLALqgtNCswGYAMw/0j5iPSp74LoPeR44XngP+Kl5tDsDfKM+Hr96wBeARb+9fnS83jvSezY6Svnn+h97S7uxPPz93z3Y/1YAMkDdQy5FOQkzigJKD8mkBXqEtAIQf57++rtVe0p6Trn5O9m8Eb18Ply+2H+K/5o/Xf5LfhM+f318ffp+fL7oQEFBO4JvA7ODwQSHRBrDdYKnQSk/b72HfIr7Ujqq+yE7snzPvn3/JECxwYaDfMSoBagGvoYShWFEpwQdBAdEC8RCRLMEQQSRRK/D2EMZghHAbP6mfWG7wDqAuUG4Q/eR95U4grmeOsO8Uf2vvr/+xf7lfkU9fnxUe9f6z7s7e0u7rXyXvfq9Sz5YPqn+t0A8wceDkscnSdpJqYo2R6iFqkQtgSN/nb0v+2v6n7nM+kI7AjwZPXQ91L9Pv82/Ub8mvgY9vfz3fOb9Ov01fjC+34AhQj3DIMSIhNWEhsT/g3eB3wBAfrf89jwJe2O7WbxQPUE+nv+ygNQB3kKKw/pEqQURBM8ELwNjwwIDQoOlhDnEcAS9xGFEBAPlwtxBtX/0vuN9erwe+2856LlS+TG5PTmW+rD8OnzcvVi9zT3Mva789/xVvBz7sTuve9k7xrzX/bT+n782/ih+dD2vv5KB7YL+x05KNsppypJI/wXDRFWCLr7vPVE61bmqeeI5JjuWPK684r51/li/P37vfqP9xX1y/RW8sfyjvaR+IH/gQVUC4gSOBJYFAcTexCVDt8HjQFH+R70lvB47Ubx5fOD+OL9IwAkBZsH1QvDDnQQ5hAIDiILdwqdDAQNphBXEk0VkRaWFBMVHhB4DHgHF/5U+Q/1QPDf7Krpt+nr587o/uy57mbx3/FK8vzy5vDV71fu0O287gDv2PNn84v4UvoJ+E79UPe6+Kj37vaY/cUECQ+xHQUtVSx/LGYjVBgQEqUEqv1R9Lntt+mV5rbrU+1V9Eb5WPmg/U37A/nD9FvyKvCg7e3vFPHr9Df5Sv6dBR8NdxIqFQEW4RTiEuENTQYzAaz7MvaF9CPzkfVN+q78OwFmA64FwAjoB4kLzwt0C7kKtwcnC4kLbQ69EmsUBBfxFQQUZg+eC4QGPf65+CDzc++x7e7sG+rx6dbrIuy17qvvJfPG9P70gfZK9CTzCO6F7EXw1u7M9b/37PU+/tj73P2mAfn5R/uw+Y/7dQJdCAYe9iWIKY4qhB0CGiQOrAXK/2r0Wu+a6v/qRe3Q8r/2xfdC+137Rfr59UzxefCv7Vztt+6c8cD1ZfkLAB4GOQxgDx8QAQ9sDo4MxgabBGX/0vq3+p/3g/lf/af//QOQBeQH8weBB4oGiQZTCDoGRgbHBT8H9AnGDJAQ4xGpE/8Riw3KCv8GzgFF/HD21vGG7sPsxOsu7FDtbe2R78PypPaU9ob3J/lp9V7zHfDp7uXtoO/S81D2j/n7/AT8EPoe+9H3ifdO9DH0ifgR+/8DqxGrHR8lGySNGxcWUwwNBREA1/j59CjwvvFB9Sb5a/9w/z8BVQCn/fP7QvQ+8k7uKepc7Abvi/F09VH75f4HBrILWgybDIAK2AeUAyH92PiS9rT0Y/az+CD+wQX6CXAQ8hCpD88OHAhIBY0EhwSQBIMFCAjxC7cRvBTpFoEW8hIyD/sIkwME/3r5U/Qu8RbxevJd827xt/Ax8UPx+/Ho84n04vS/9cP2kfaX9ZX4GfhR+r76ZvoDAvT9tvsV+iHw0PLi8PPuQPOO7ynvPfPh98/7BQsPGRYZsxt1EzkJNAryAJz9Xv8P+Xr9av+EAtwKEQkEChEHYQIsAi/8JPhe9UbzU/Lx80T3qffK+lv6jfr8/QX8Z/z9+fv2U/Zu817z3/XV+S/7lAAzBFsGTAwHEDwRKhHFEOsNWw6HDssQohRjFt8U+xLgE00QSw75C1sGjwKj/GL4oPfg9Rn0z/GX8dTwtPKg8tPx0PJe8RjyzPDH80r0VPUC+qf8UwMxBBAF5AfbBwoFjwEX++fxSvEd6Snqs/B47lj36vay82v2OvBJ7hfzkvFw/nEHBAehDZEGIArFC/0HewpgBCUE5QLlAWwI9wuSCzgJzAhSB6wDYwDb+7P6WvlR+KL5+/oo+VH2wPZT9WHzaPLs73XtXu4o74rxtPNF+OL+6/0OAtcHywl4DaUM7AztDcUNgA74ENwU3xWVGREYahTRE0gQSwz2Bb4Dav8L/Ar76/hw+ln43fjU+Xn5E/nw9Yz08fS48pfyofJu99v5T/kyBzUJFwWuBP4AGAH2/wL+lv4o+0f7wvaa9vr7XfE49zz3qPIO8P/naedT4hTla+eB6fXsKuxc9bkCkwXyB20HugOcAAYCdQYeBG4DpgQGCIsLlxALEzsSjxKUECQMYgqjCGwCAAAE/Wj5bfie9+T1jPW19G7yovGb7+PvFfBK8Y705/h7+cL5j/tn/CgAeQBkBecFMAYuCXAHRAnTCMkKGhEoE34TRBanEvIQ0w7WBnIEuAKI/dT+If/G/aYCOgTQBhMFcAJjAM38gfqq+V36Ifv3+yH+YgMfBPEH2AWtAHT+Bv3y/aL9IPlA9bX4LvQT9i/5EvRY+Gr7vPuPAN78jfm49BDvnvOB7/Xucetx7PD3KPOH9H/wz/Jq96nsPu+Z7/X1j/n5+5sDGwThAMwFewmAAtQByf1+AXwDwwN6DOYQew4tDo8QyQzACnwIgASdBB8As/9uBJcCLgO+/nb8ifsR9/D3Sfhi94/4wPlI+nb7TPqe/Gn7+vnx/5P9pQBwBmAERgKkA9AG4AdAByoLTg6+DukSJwdmDwoS2AcgFBwK0QirE/AAe/9AB90CMggJ+1n04ftp+fLqlupQ8Kn46vSe9bMFHvhH+uH0UQDT+b34qwbg8WAAmgN+BTwCYAA1B58Gw/6k9eYJywJ38vj7UfpYA7L4FvBeAont5PQQ9MXvg/Mj6sD7rPDX8SH3vfJL+bvzV/bn/38D2waV9v79Ywme/ZP7FQZoCdb9uQMs+/oMJgPc9eL+/fOeAnT6UPkw/+T9Bffl9/v82/ggBuz0QvRZA1bxf/yTBW7/2AM0A/8EcwgaB+kJWg2gEG8K9AiGDMIGGwhKENwC1QfJCEf57QSe8gIKQPIT8ST9mvHZASnpewrq+gwAEgsJ9Hz9MPql/oT+HPBoEcYDYvRVAmQAYxyE7gf+8xRHBcP3/P2VFuX38+yQARMQL/hi61r/7Pf//MXhdf2vDH7kuwUM7GUFtwAS6uIA/BTt9mAEERBq6G0LYPpwCFz2H/VjEqEBBu3sAgYMrvUr9dn4jfvi8sjtM+7z/e/tD/XECqzzA/MqAy746/aE+y8Fc+eaBX8SQPXT/x4FzxUZ8D3+tRtuDUT6BPokBwMJ2/ft984T4gKH8GsIPQWw/cr1mfBECcD3gvVi+b4G9wIE+MkDPQT2CXH1RwCQBMT6dv6dAFECCACLBSkPMf7G+YUMoPjjD9bo+gxVCGXvZhLe9hIGT+iuEa7zowV19LoD6f/w+Nn75+4SKNTQjxtbAH76Ee6nB7wHx/1BDdnXTC223tIE8fkWBLgdedYUBJ0AwADL4xADafOh7acSdOY6FYj00fP6ERbs3ven/S/5rv+XCZvt8hTvDsDsogJTBTn5uvwy/Iv/9xXq7CP+jAsd9Svtmfw3DVHvjAh18X0EeANx7ycOmu2TAVn9iABc/+MHdv5T9XQKY/M8E1H6EPP+EnTkKP/1DHD8ZRCb57EQi/eo82ELufk9C0bi8SHd/yT4ywhZ5l0Y1OwZBcoHz+9dGkvcVhEY++UD6hqF1ZAk4OyBAgIFcPCCFHjz0QYYBzT0tPcRBnj6LPj1+5j7H/m5/+IHeupfA1f9KupyAQ3pOA8m8nP73An79uMNh+W8E6wDW+UpHkjroxAa/ZbjMSfK8PT8PvVq+kj6iAPJ9HL7ug+04mgGNPBm+qsAbeX2D2TuZAgLAALnchv02G0Fsf7P/PAHw99uGv77s/G/DtkD3PuC+70AevdpEVH9EOonIPDti/TRCQ79bfst9TUB1wDm8ZQI6Qqn/ZoBv+/jGtPnZ/8q/RkJhw1e3sUgqfLOBPgANfaYD6IG1u5QDRcRVeP/G5jt3gC798zvnxRr4VcRz/tj848Um+VMAHr/f+z0F1Lu//+jAUT6WwY+8PQKiAZfAmP3kv7CACP9oAzT/d78/Qkv9Qb/EgUrALLpaBYZ7lT2Vh6/wkUeOQiV36kKhPUyBw/8tvHjEjnu7PomBK/0iwMDAeHxdwBzD4fmfw2P8TcOmfSX+bkQGOwOGjLjJvjsEhLq3wGuB8XzxgHO/GEII/Xt+xgCggOU9JsLfASA7FQULuN8GFD6IAL3+Rf2BRsb57sMNgKv/vv2RxXO9Z77ugdN9eQICegcDLAL3vWG9ooUJOuvCLUJhOKSEjHmTSAd5t3+XyJL3D4UKPE4Ef33uvsnC2732wXIASkCfgLdCdz0WgQBAzoCP+lCEFwCH+/5ADcGXfFQ/Sog/+DMFY/ffAmBDbzSZDFJ57X+Hwi29GQAWP9O/UHtDw3t77QMgvbM/DgHger+Dyz5u/YcEpDy+O1YDXH33QLw/oz8KfuE/Mb4vPRDFSTu8Aa9/u3qGhqI50ENnP625jYSYv9TAXT2iRHX90UHLvdo/tYLN+dpEsvxiwaG/lcBCgvQ+O73kweE/yft3w9E8aD4nPypCX/6tAB0/Znyjg9V7ykGowX1+I36tPwdBlQGvf8y960KgPzw9PMJswT1+gX8SAWMATj/UgRG70gNkPLd+7YWTeSUG//fZhGTADjlBxac8tYYR958Ezz6eAS495Tvtw0b+gUBKObtGGfzfP4oBxj7vvTEB8ftAgvRDpDOVC3/4tkGugX15akeE9ZgH3TjZP4bDvjutQnD9BkSi+akDGL42wGq+5z+tA3X62sI8/0c/7T9NPg1DhLvq/8oEKzpAAcUC4P15fzGA83zrf5h9I8FZv7/DO7xYvRFEmPkKBMG+2r+4Q6k+LL1/wSJAoXx/QPuBhnxsA8sAI71dAy/+DT+YP18B8LzthRq99r7UwNJ8swRGfi6BP4D/uUzEy8DifPeCvfyFBja7LkIM/huBxT/SPg9CwnyWRBd6GsZBdrgE4cMfuR9GJHqlSD07Q/oniIy8dvoYBe67awbX+dj6pgy8db8D7TzkQje8lz3qRS++o4AG/CIGj7n/Rhh7PQC5AqZ3jYV1vrQB1P8NfdSACoMjeOUE7H6T+ivIW/fihR+9Wr9ZAFV8+sO9uQeKUneYhAE9YzxcB5y3kkdnvBVDWXn7Qtw/hQANgxb6FUdeOi/DIT8AfuvCpvvPQjL/C76ghHJ7kwAbQrc/kv/yf/r9pnzPRhI6EoLAf1CEb778OaALFzhjwSm8oEMaQHB7wobBPFPDKjt6wT+AwD1HQCBBKMICPDl/vwDLAWP7uT5dCCH6QP1dxZ96scWrezS8HwfzujrAREBCADBAwf1XAa8Ccn8Uu9RBdL0aQFZ+4X82xTB4xsbv+538hwVm+GJEkkDAPQ6Ajf4hQJU/e75bAIV+g0AhvYCBjP6Rvw+FiTm+gmTE4XZ6hjp7On/+g+f3gIl9OjI+yL7xRJo633ydx0Y2Usp5OOHCAoI7euvBGr0MxMN9/Hxdf0gGMfgKhWe7tcQ0QfB0U4pk+nNAC39hP6zAJ0QC+vkBsH68u51HLLfFRJTCG310fmZElvpXQlD/wj7ZwqZ6fgbSOfUDibzh/aDGNryufuCDUQAAd/lHDn2P/CAHEnhewQ9E8Lspf70BMXvugAqE3jgyg75C0Do8g0e7kEJxAQ66KMNwQQV+Ar3PBFR9DvzNxOR6YEKRv2y9bUIcgIT/tbzkgdZ+PH5Hgyo9VH1agpv88EArQNf+Ar13Az4+GT1YxMn8lkGye+z9TcXwvah9fUU2ePiAW8CIvWBESrrghCG42AN0wop5jokNN/WANkNreqmApsKBvXm94Mfb9ZFFvQJ3+PpEMv/TwBe+0cDJvViDTTrxxc38XgC+heqzNIbZPTS/2AF1QUf/vfnPiNw1poYa/QW980XUNuPKf7aVQ9wAV/z0Qrw7FYQ4PUBCKD5jAAlC83vfAG3+toHAOk1FxAETec8L+zErxrYDknbfg9u/sgDegCP8uQFSQM89AsPduM/GfXrNPubG6LgDxM68b0Ccfvv78gnTtakBEQhKte+GO0LJ9e3DBoJP9sAHpL+DO9EKv/PzxE9BDTdXitbzYkU/A5+6CgQtvQAGPfk3PZdIJfeiA2aBcDmQSfD7iP1fhnf3qMQCvte6jcoSOZjGMLyo+rnGFP5IPPlCiv+4+vwFUfisClx4VcE4w0d6okSMdwvH8D0ov8p/iwLMug6FI333e8JJSDSViQL4HciyPMY63QVvO3nF/vYsh+D/lz3WPD4F531hO71DJbuUBdX5Asb6u0X+VAk1dROCm8R59UbG8b2bPjDI5XK5hxu/I3thQ7r/fH93/s2/Hn/3Rt6yFUmbfYD6CQh4+SCC8bz4f2G9HUO0vyFBA31mfsJDFjeQSpOzHkbbw1H4sIdROQ+IRbFaCZH6sX9+hWY6BMhE8q8LD/cnxi8+hbtzxxjyao21OBD/7gTKONtJtzVgg3vERjU5xX5EPvnxAWDBkT+6/EN+mYhPetP9Y34th5+4qEHHgSX/L0JTtwPGt7jFimB3OYL9gHt/CYGQuizGuLTtDCe1gv/bBXN7gMNQfArGHrkT/W/DYTnCxEFDqDzDvXRB58O0M/cK5fl1uziLgnT8B/V6v34URJg9JX9PAMMDGzmEvnMCDoCuvxM8lkOmhKt2RD8jgycB4flzQZVG3/f1Qvj7XQKMRI4yZ82S+eI6bcv+uLvCIvnChRK5lEH/QOwFBvq2usBNkG/hCen9TABWvhy8gsjutk9GCcD/uf0IjDiPwdDECLg1Rx+3wUHzxkY5uwOYAaA6BwOR+ibB9kX/OZCG2rfXQOfEjjgkhUqDC7s7ANfA9X5zwbf6mgLYAf55fUb4ALO7xME+vYg++v74BRQ6wccwukg+OQQCup8E/fm8iQA5AMQqeP2CPUPjek1C3z97wzu34UfG+w0CnDt0QZNCCjuTQroByrvCwM6+Wj7VgwK6Ecnteuu+w8Jm/HH8QMckOR6DkH8Sd9SL3rgIxoy63H3FxCc7UsBevdOGQPuLPEdGY8Ll9KzGgcRgcpjKZblOwrWDSzkQg0PEZbm7QOMESzh5yOd0A0c3fwn6NgfNvptB8DuNQoW8VAEpvPmBRr8/Q0P/G74IxOd1ZwXsfABAlMTt/G7ESvgcgsIBtPpwhjp9Ar3awm26cITNQBT6LceLvWXAlkBIOv7B+n2G/u1DGruShq6+QbnNixszgASh+u0CFIb08knKITyLw0m5SAG+RE84Vz/WArpArb07QKO9YMUxukY/foRGeeXBg0TXNqQIz/uv+/wJpnLLxq/+TXssRSW9F0GYwNFAEsBCu22+lcQXfgq5e0sO+BXAfcS7uB9J6LD4xtICC3u/BeC5IgBMRB/+pbzZwt25GQQEwNg+vD5GROO5vb4NCP/yRswKeHLC6IEFdyJOdXEAxfB+DYDLvNDA0IZ28tVPYLBCSCDCZ/ZNBzF6IYR+PRvBLTlCipA578AiwEY+eYbQsw3IzL2cPzoCSD3LPr2DGrzFPJ6EWLt+hhv6bYFPBL/7zH+i/AEDLzz3f2vGPzst/zFEFvhbRp95/HpSSLr77ACog3PCbHalAsV/DPzfBfX69cDKwcj+ZP9o/rT/v4Ii/ok/GQBjP2PAq7x+gTT/80AvgSi+8wM0+16/bcACfj/BWgH8vEOC7sE7+xzCPX5of0XAef3NAEGFvzqTgk0+c76PQuu6voMg/bz//4DqwSS8eMHZAhY+Bv67vtVBlbthwxmAGj5EQQuAZUCZ/db92YNdOHjDRQX/d4wKY3cWwWzBk7f5xeJ8ycNpvkKArD8SQNA/4z5IQJ653MncuHH81Alm94CDjf4xAuv9in92Qbi7WQROuxoAw0J4vaO/ssJX+qkC1f8Rgb78nXzmyQP3TQR+gEy8Lj/X/7CC6H7pPJTB3sCLe/CCp8Ni+OXGY/04OukIwLMMysB9YTr4hp46jcNePV5ArH+s/pRBJQF2+7gEJbu4ftaEa7uCApj/I0DB/VZCZf3SPuoArXw/xd6+mf33ggL+Xv+m/KQBvL8EgFYCAHjsB6J+TXschsc62bz4A+j9pr4Iwuk+7D6rgMfAUz8rP80+bf91gZS9XIK+fxh8gcXI+2d7tkQDAYI9lcJ6fiLB3j+m+vgD4Lz/PEFC7EKbPbJFGDf8w7qBETpdggA8iEkctfbChsGkvauBEkEmAfZ4UwZ3vKt+/gAY/7E/a4CmgLD9sMOL/iN/8v9q/ldB/f2A/RuEbj3+P0HFnrsC/agELz0pvMQChALHfPZ/ZQFhP+S/f72UATb/EcJxvLVCHX7tPRMEq3vWga/A6z2WQodAGTx8gHK+fsNC/KH8nAUDv43+av8DhTU+mD7De2pEDDv6PpTIlDbqgv2/zIEH/9q8qMPx/Nj68EWz+zv/2MW0+zQEXvzQ/+9/2318P6t+JoIhgzV6zEFtg4/3/oO+QBIAzYQCuAZCRH8w+GbGosHMP7fBtHoxAvj9fb7AA6r8KYUC/Xb7aYPnPe1/KMFEu/nGqP1hvdyIGfYg/QsEbQBAP6TA8gGUPqO8Z/9BQeBBujuQQElF6YAMfyp+Tb/FgDz62r8ABRW8VoVQfqX+RgMYegJCAr0NP/BBzX6lgQ5BLLzOAVYCVzxeA/f7PrucxWJ8ub75gZy/WQA7Api/3X+aPwW8KwGQvGIDAYFPvX7FpLyAQBb+dD/xPdRAcMHHvq/Fsb0bwa29PD0JvcS/Jb+FwL5EzXxEhyy+Ffm1Aj+8Wv3fgBn9G0UGwkk/bALJPu2//XtIgiu7nT8ywLM7s4NiBL/CIn1Swy35wv88PoR+FgM7PmbE5f6T/fy/hf/HvxlAQj5h/eL/a8Bngyv8HMXgwQy5yIKt+vV+1sPQ/ncBvwLK/Rt++XzaP8eB8rt8RK1Byr0gP3AAgQCs/eQA1r2XP0gBeb6Ugrd/tn3NQW0++/6cwJZ9XX//wLY9zAMmgX/9///m/oa+kgH4Pa/+qgCx/iSCrwE9fvHA/Tqz/30DAnuCA+6APH3yAVI9CsF0ASv/Bf3OvcT/IwKtwOu8wIFvfszAfL9uv7cBib65fwN9CAFS/ch/MIEnf8nAdYAUggi9pv+S/iB+xP+CQLqBaf5Cwan/mb7NQJd+ZL9TQKaAur96QLf9qj2lP/P/+4HGPxCBnL9Af9J+If5dgE6+6wER//d/X381wHpAIAELPVi/XsDGviuBWz6dv9oB6n8Qfqh+9sA2f/R+/4CTANh/2MBevaU+h8Ct/iaAfkBGQc/AJ345wUC+Zv6N/8R+hn+5wGo/fgE+v+X/dMGUff0+1P+q/f1BE4F5vpPBPX7IAB3/hD7HQDb9X0CagB0BvX99PgtAHj+7f1G/5b8D/27BJ35twUx/qIA0QA7+xECevuP/3793/4Z+c8EvfxQBX4BvPMbCcH29P9wAtX5uwDI/m0BtAK//d78UgMX/bX7S/5J/jUA4P5I/xEBzgCA/yD97wDU/+D6swMR/ob77gNM/a4BQf1g/m8DdvycAgwAoP2EAO7+x/3m/Tn/fgG+/or9bAQmAAf9z/+C+bIAq//X/YQD9f5hAFP6SAISArn8Yv+x+pkD6f57/RIBqP1BAbz/XwAxAID+Bf9Y/ZT/uv5VAMABMf56Afv+8fw9APb+E/5oALr/u/4V/pn9k/09AY4An/1OA1b9IP+I/1P8NQFHAPn+cf0aAZn8dP2HAnX/bgB7/+37rwBaAMn6hAMh/jT+XQK7/LoBG//r/AsB9P6K/RYCmvzGAVT+jfwFA9T7xwCy/Pj/ZQBz/n0AM/5N/bX+6v/T/NsDUv6AACj+s/xEAuL6vwHg//X8sQBD/Hb/LQEW+3QCHgHn+5f/EP/F/un9tf/j/c4AYP8d/F4Ccv7p/Q0BOvszAM/+d/y6AiP9jPxGAA7+QP8dASv9F/8wAE39yv17/Q7/cf/F/kr+/wEGAJT7kv87/mP9Gf7K/yX/VwDD/OD/dANP+hYBiP3G/AcBPvzW/jUCwf2H/iQC0fsXAHr89P7S/636iwFM/k4AKP9I/Kn/Pf5y/BsAlPx9/pwCrPyV/0P+Z/25/kz+Zf3bABr+if0mAcL7HwAU/sX+VAAw/vT+T/7k/9j+Lv55/2r+Iv+L/0H8kgAO/e3+hACU/gP/sf1gAAb9pv4wAIP+GPyVAAL9EP4TAXn7SQGA/vL+Xf8g/pP+ov1+/4z7ff85ADb9EwC//TP/5v7u/EP/tP5F/u/+c//0/KD+9P8O/QwAK/9h/t3+Uv5kAFj+6P42/mP/3v9c/c7+r/+D/k3+8gDc/EIA5v0m/vYAafuGAv/9g/4LASf9NQAV/QT/Yf+d+0EAI/+d/pH/hf25APb/wf0Z/uv+df2H/1r+G//B/zr+qv8I/egAXP0D/h0AC/6g/7H/TP6z/XQAWP6s/63+Mv5X/7L/Of1fALv/EP2+/8P9EwAD/rEAZf3z/vP+wP0RAPH8oALA+3z/AQJ0+wsAJ/+5/YkAkf/p/ZAAo/4JAIn/q/4kAV7+1f34/3H/dv0u/wQAXf+A/wQAmf25/zT+ZP54AGP9IgEi/ygAuP8b/sT/3/1D/37/ev71/8f+0ADV/u393AAW/dgATP35/iYAKf2eAeD9X/5c/w3/y/+s/ej+L/9//r/+9v0hABP+5v0X/7X90/8p/iT+UgGa/dr+s/88/VQAOv3u/xv/tf24AAL9af90/ov+Xv9S/q7/s/0FAMP+n/7C/9b8kgBy/ib9/P9N/WT/Fv9g/e3//P0a/o7/GP6l/jL/4f7A/qX+C//D/fD/dP4b/cAARv6J/tL/gP5s/0L+lP6K/1j9BwFm/QP/sAC2/B8A1/1Z/3n+Sv03AMD+aP6Z/+b+h/+g/sP+gf4f/rP/Nv4b/XAAN/49/okAovy3/1X9Ff+2/z/9IQGd/D7+KwBR/Uv/Kf54/vn+y/5X/hz/1P2E/hcASPyoAE3+oP3H/8T9tP7+/gD+N/6M/8f9hP95/ZL/I//F/d//L/1K/xT/If4J/zP/Hf2E/wH/i/3j/lj9s/53/uT9CgD4/7386v4z/y3+KP0a/9z/7v1a/yr/Ff/A/T0AKf21/k0AY/xjADX+W/79ALj9Bf98/1z9Hv81/jr+Pf9y/iL/JwD7/nX+Nv++/sP++P5F/4L+af9h/mj+XwDc/qb9agD8/jr+xv80/uX/Sv4+AMz+H/46AD3+5f9H/v7+yv9c/jH/+//Y/Vv/6P8X/dcA4/5q/i0AjP4GAOT+//6v/y7/Zf5RABP+4/4zALv9XAAY/gsAKgBA/oH//f6F/pz/ev5q/6//FAC7/zX+tgCx/VkAH/7l/jMAoP4/AP/+xP9V/3v/mP7V/iL/mP+x/X8AsP+o/m0AeP4BAPX+T/4BANr+rv4LALf+3P93/rH+Sv83/xb/8P2O/9T+qf6M/ioAEf7f/vj/Y/7Y/5z+OADN/vb+x/7s/rL/7/3d/xn+vP6RAOL9Lv9tAOr9rf8A/3H+2/+P/lX/Uv9w/t3/1v5e/dIAi/6S/RUAyP6B/3/+aP9s/xX+hP+b/isAn/1P//n/SP2GANr9vf/O/oz/Bf/P/sEAGf2iANP+Zv8A/g7+m/8v/XT/Pv+Y//H+s//K/nj+1/74/Q7/jf7W/nL/qP65/sH/4P6w/jX/Av56/37+bP7U/5X9mv/X/hj+Kv8i/5v+c//Y/gT+4/+5/Yr/i/7w/pb+Rv5N/+D+zv89/WAA4v3f/db/+v2s/lz+Kv/4/nD/J/5H///+CP41/6T9P/8T/5X+1P5D/yv/RP46/yz+Zv5v/vf+rf2L//3+nP7S/xj+3v/B/ZP/W/5i/l//rv3h/9j+bf5s//r+9P39/mn+vP4S/4f+AP/n/in/D/6U/qf++v1t/8X9m/6g/yv+Wf8j/hX++f1E/s7+gf4B//H+MP4P/j7+3P31/hz+tf6e/hz/n/56/sf+Uf7s/mT9AAD7/Tr+U/+V/pr/Sf7P/uX98v4h/nX+p/5N/uH+HP44//r9Iv9+/U7+ev/H/MT/Z/7x/pD/0P26/sz9Xf5b/uj9pf6V/uD+If8d/lz+Uf4a/m/+Gv69/h//wP5d/n3+D/5K/nn+F/4q/sH+lv4c/lv/ef7I/mH+bf5I/+792f4c/2b+G/6y/iT/Cv+R/q/+e/5a/iH+Sv4y/n7+u/8R/6//FP/R/uH9vf5L/jH+AQCP/cj+wf51/nz+cf4D/5z9kf2p/oL+Tv4A/wT/Wf87/tP+N/7e/bv/AP74/Xf/0v4D/7n/mf6N/if//f0U/sX+v/7N///+pv5Z/xv+c/6l/vn9nP6M/vH+wP9Y/hv/h/6n/Ur/Bf7F/or++P3d/yv+yv58/4f9df55/t39a/7J/oP+R/5L/hb/ev7y/g7/TP5b/83+Hv5i/jP/F/69/kL+yP1c/jD+zf6//s/+e/6s/iD+Cv6D/l7+Hv7j/hj+lP62/lD+PP8N/rj+EP6x/Yv+Kf0+/if/Df5r/0r/Yf5I/lz9E/7P/YD+Z/78/Qv/e/6k/nH+D/7Z/aD+zf2u/Ur+2/0u/nj+mv5N/RD+U/5T/kz+kv5w/hD+yv43/u39X/2//in+iv2g/vr9hv5W/gz+Hv4h/kL++v23/S/+e/6V/lP+w/0q/rH9s/0+/SL+a/7p/Qb/E/79/Zb+7/3t/eD+/P1P/iT+8/3G/kT+M/6f/mX+jP7I/qL9fP6K/d79Hf46/tj+q/4a/nT99v1r/bf+CP6e/qL+mf3B/RH+7f0V/Ur+F/41/tn+0f3u/aX+p/2p/uH+D/7R/uD98P3Y/Tv9Cv5O/mv+kP4L/07+Af7+/aL9s/7y/mz++v3k/XH+mv47/rD+Lv7K/kj/Pf7X/hX+l/3e/hf/X/6B/nP+U/2O/m7+kP2d/nD+nf48/jf+bf7+/WX+JP7m/Vr+y/7o/mD+2f6F/mj+gP4i/m/+ef7I/nX+xv7L/Xf+w/54/kr/Ff6m/kb+O/6l/qr+9v5Z/sH+v/5Q/3X+Mf66/s39fP+K/nD+4P4M/tz+mP7U/v3+HwDd/qv+lP4u/i//ef6//0f/bP7Y/rH/o//x/jn+JP7H/sb+RP5w/wIAFf+i/rb+OwBa/yUA+v5j/9H+7P7B/77+bgAE/6T+dv6i/+/+cP6T/hD/4P7//tn+kf8KAFoAOwA5/zr/3v63/wH+KP+G/nkCfgQ4BFICAP1E+cf38/cF/a0BSQzcCh4NxhnMAqX13Ob15fPq0vX/BSgL9QYFBwAaOA+pFQkNgvnv5fXW6t006VIBrRFGH7MfAxkgCMrwp98N4ELtSv5EDScUqBOjDMIATfaz9QDzyvcg/KH+7AEXAwUEBQU3BJkBDgC4+wP5i/f0/PkDvArJCo4GJgL2+hf1j/Hl89b66QOxCUoK1gbVAj3/afur9PX0Evho/aEA4wJnCPsHnAVh+Vb6l/sz8IfvKPOzAu4P8hZRFtwDFPSK53bl8OrG9aEHyRT5GqYVRwWj8k7pTug98bMArw1qFbkQmwPo9pft/u078Ur7KgaUCvIMDAjs/cjyPfPz9aD4qwEvCA4K2AYQ/wX69faN9/D7mwFpBOUB2wRrAT39zvxa9t76dwf4CJEFhQLC/Tn2j/JZ9ef2VvrT/lMCDwZTBykBt/2H+6L59fn3+38AqgNuAhD+2f8v/7H9OPyf//AApP+9AkwBJfxf98P6JfzG/t3/Uf/OAokEBgSS/3H77vJn7HfvQPvrBZEL/g3NBPr8WPmE93/7Of9LA/ICpgCnACH8t/rq+uX6W/xI/vQERwdWBnMBVfyC+mT5mvyr/toBDwCZ/zkBMPwN+4b50/uz/gAAjwSQBFz/pfzC/J39JP7l+8v7UPyX/QT7+wABBXYDEgJR/KT+lvnj+2X/2/4MBTYEmAIg/U78r/kp+oj8PPyrAxoDqASc+mf2G/0a/NYCmAecBzUC5/i38Un22f8lA1cE/gd0BowBbPyA9fvyOfFS83H9BQWdCm8JeAdODNkECfjq8Nn0RfqEBC4Pkgu5BSABuvid/DAOMA9Y/fDv9vDr8cr3cP7j/Sf96Pxn+Rn97/8d/Y/7nf1MB3oH5ASD/tD5aPZu/JIOLBa8DbP8JvXO8+XvWvbP/NP5JAYfD+cJAwMt+Cv0LvVK+OEAbP80Arb91wAJDJsHQwVs+8n3FO//8ET/5Ao3EfQP6ApB/er1mvHH5p3osP1zB2QO6g9jD1YHKvH/5QDn2vJ9BUsa/yCOG6oGJ/as83Thk+aH+HUDKBGmDYQE4vSN4oHpawAUDeQOQwclAUD8Efi8+5oFcAUMApsF6AP+/k75hfq49iL4kP7lCJEJNPwGAHv5RvYG/eP7igi1C0r6nvmv+4nxqvfs9VvzpAELB6kL0wbD/DD0Ku559gcEmQt4C5f+6vSpAF78hvkUAwIBYgVPAWj/owSP+pz3m/pZ/UMA4wXGCdD/a/vY9zDyje+e7KP8IRaiFB0LH/5Y7jjmvNxq8iMQJxuVIJIX//wv4zTgsu/vBJYLLwmL/qz2zgEmA04GugMW86HqVPIsA+cKFQ0gBasCE/y37Rr1ufqeBAEUhhFrCf/5Y+hO5e73FgbxDxgQ9AJJAxz2tPGf9VvvuvHD/gELCgmUCW4IiPsq7vbmfO+RBZ8KzhQyHCgKP/tl6Yvwo/hz8p3/ZhAOEwgHlPw98t716faTAHcFJf8HBQr6TvhK93ADThO4BhD03O0j+Hv9aAQvBNAEoQXh9cjz1fvhACIHkQa5+6/xsva2BN4NXgS9+Jj3bPUoACEP1RIlB1P9ffjv8R7wk/MvCH0Q3wrmDfMDSfhz92vwSfu+/jb9NgVrAlUImAKJAwgDwvYX83Xvg/ecAYIGLwgW/Z71KP3OBfYBvP91Agf7YflzAJgKWglHA6f6dPo8AcL36fii9wYGKwr3+yQITgVZ/+zxpPTzA08Bnv/K/hcJE/7n9kr/wP1n/Ob7tQILBgL9EPZC+Gb7PQYzDKUDPf1C+2EEJf/X9jX+vf9KAa78d/85AFQEpQ34BSv6V/SQ9MrwW/NuBJkUHAsP+oD6SwAl+6v7MgGB9yz3uP2GCsYI1/eZASsBPwA/A5z5l/zF9w35tABqBM0HLAKYAT36N/Sg/8cHiv6P9Cj2//uCBgQFjQb7AkH0mfHb9q4I1AtTCcH/cvcr+CL1ovQY/ugYORX8AVPztut0+Pr+Yf93BcMBdf9RBQMAV/5V/nz0gvY8/0UBZAPn/uD6ZvzE/OH4hP9I+6X1twK5BI0I4wWD+AfsSO5y/N4RxhOS/YX+jf399Y/1DPla+gH8ZP/FCZ8Jmfvr+S7wEvJm/aUFfgqqBwv/i/xWB07/yvLH9zL51vomAiMIyAirAB76jvtTALf+hgNRAAr5kvuj/mT/Kf9BBEwE9/wv9ov6Y/lh+XgCNv5RAQAMYQUmAKn1EPNS/pP/QQAY/gMB5P8WAFQDav71+8zyYPfDBF4BVgZxAXr60gPY/S8CkgX8+Mb0mPw4AZIAjgIf/BL/TgIUA3sF9QIX9xrvxfiLAegFEQQUBDgB/vhQ9iT6cfuM/QQATQKpAgn9svjR/pwBoP+MBov7lvlz/db81gGgAisCh/6Q/T7/LQKA/Qn/Gv7hAHkD9v3j/8L6DPjF/ckAcwFT/Yb0cfhBBV4LrgvvBpz4JvMf9IT8fgqpCs0C/Pos+Gz17/5YBzAD6ACS/Rj4LvoH+zX98wYFAwf7rvws/kT/MQKF/3X+evlA9hj9O/6aArYGTgOQAxYCqwG8AOj41Pms/QP9TfwsAeADOAMWBrkDvAAC/VP8U/cT9Bf6UgLiDcAKoP9N+iT5Q/vqADsBKP32/p3/6wFUA8397f1mAFH+pwBmA3UBNP0N/Qj69/f1/6oAX/0g/8EE7AbuAO/6ZvY2+x3/Xf3CBbwEPACoAp0BwP/v/ZL/cAGw/wz8vP4F/1L6i/q+/p8CgQWMApb4s/bK+UL8JgEwAK/9zPxn9an1fPpA+/T8OwGAA/j+8vo9+L/5zPxv/sP8e/wq/Q37C/pe/ToByf4cAJP9D/uO+yL5e/ef+sX8rPpu/3wCZQVRAUT5AfhH9qT2XfxpA8MH8AW/Au4CPwBe/az9ef6o/VgBtwGJAgQF6gPwBpcDVv0MAesEHwIVAbMAjwLZBEUDKgE2BJIETADK/tf97wBTA30Arf4SAWb+Vfwa/77/UgC8/Uf6Af8IA1UADv6p+2z6uv2p/jD9vwHDART93vg89z35bPmE+NL2QPmg/ZL82PjJ9T/1OPWi9HHypO5O8Onvku9+9aT6d/ui+ZP27PHq7w/xF/BJ8av3FPxD/mX+vv6P/ZT9EQDQAoQJcQz6DpwRxQ3qC3kHaQRYB/AJiQqVC7sLmgbvCFkH/gFHADf8s/yM/Ij8V/5v/1/+TPxx+xv4gfVt9Nb2lPx9AGMCVgM3BB0DqQIMAcIA2AMoBhoIXQmXDI8MfAsFDBkKRQnTB1AGagTBBZQHAwcXB2wF+AMFAT38D/pU/Iz9XPw/+2/7ZPpl+Sr4Rfb39fXzJvPW81b1Avg++JX02O9n7cfq+Ohw7Qf09/VG9ZDwMufJ5fLkH+qL8nXwYfYg/YoBYAjdBjkLVRXPEJgNBge6ArELFg0tELQRpxCWEKILaQjxCMsJcwaEAb0AJgCo/wD+vPyr/QD2SvMC9dnz0PVt9wX4IPbI9633afi/+pn42fz+/qD85P3cAboG0wtlDmcM2w2aDbkMfw//DWUP4BOIEhwSNRCMDCAMCgqqCKMHZQa0BA4FzAWYBJ0B+/2Y+7H4ffik+aH6Afy8/EH94/t3+UD62vhx+Xn5rPc0+r/6kPtg/AT7mPeb9zj3APUP9LX0D/YB9kX1pPHI7Xfp/+lN6APpIuuf6ZjtVfIS+4AChQsDEngQeA1iBRH+yP/NBKQKLhDyEIcTlRVNFOYRfg1gCKsDnP62/DD/qwEIBGkEeP+c+xj21+4M7ZDqeOup7eXwWfWo9YP1YPbe9I3zV/Ue9U/4+v/tBpQMrxCGEKEP7g5/D8UQIxO0F8gZ0RyWGcYUvRMFEfYNZQrLBTADNQNHA5UEIQVpAZX6CPXP8FXwJvLQ9Jn3yPlQ+kv6WfuR+Mn3lPfF9ev21vbQ97n6jPoL+Qb3rPaO9e7yXfPB8GXqLuhx5gjnW+uY7m/0O/e8+pj+iv6VBF0M/w6tDvwIKwUXB/wF7An0D1UTVxUcEmQSDRMaDBkEqP5a+Zz6/f5LALcC+QAU/JH5SPbc8B3uG+wq7HHwtfIh9bX3VvhG9n/0YvTl9FD3dfjp/IIDnghWDP0Mhw2VDm8Pvg76D6gSjhYnGqYYghYGFewScRBxDNEI7AahBQoILQjIBNcBVPyY9xz1g/JA8r3zU/RU9qz4vPtH/Pb6hvlA9yv3rPdR9xr3Bvlf+8z+R/8H+jL2nvEr68Xqq+c956rsNOqy7MLw3e9S9Gj4g/rTAj4N+BaSGOoQMQjnAlMDnQeXDk0PDBN2F50XmRfmER8KDAIP+lL1u/YF+Wj80P8Y/2n+O/6W+ObxGOxw5fzlmeuQ8D/3zPtV+1X7yPdN9W73OPdw+DP9JwB4BJsKSQ3ED2oRTBBmDiYOrQ8GFmIayhYSFTwTXBHLEGENbAmtBXkEngPmAmICvP89/U/53fWb863xoPEM9Hb2Bfci+d77uP3Z/Rb7K/qg+cP2yPXp9+T63vtg/Af+qPsj9svzTe+S6lznHOGJ4rzoX+sk78ruIO6x98oAegokGY8c3BUuDSMFdwIyBmAKWAq2DuAT0xd1HAEZvRCBBjD7ffT88ubykPSY+Er7hf2+/xz+gPj68ArpVeeE6Tns7fHm95f9DQDW//38o/lN+f/2j/fs+0P/5wTyCKYLTw6TDf8LdApkCoQN+BAhEWUQEBIJE30RQQ9lC9AHkAX9A4YCbgFNABr+Ivx0+oj5xPcQ9r31pfVI9Z/26fhL+0j9EP3d+mT51PiQ+If3JvVY9xn5v/dj9g30eu5M60nqhecC7TPtW+gH6kDjCuGE6fPy0wLCDQcW1SKOIscZyhHyBwYIdwo2CrMNsRDPFaEaqRqxFTIMtv8B9V7ww+7j7g3x1PMY+BX8rvxP+VH01Owr6JHohekL7nLzivlhAMUDFAQ6A6QALP5c/cf8YP7bA18HBAuMEQcTIBOkEhEPIg6fEWQS8Q5eDVEMogv6DU8Mowi/B3QEgQMAA5f/w/wW+Xb2Rvjt+EH3Bve39n33KPkZ+jD77vyd/Tv+df+C/4n91/tq+nX6mv38+yT29PJR7lLptOg56E/p5+ww7Jrm5ONM4dbjVO6l+csGigt9EwAkYSlJJCAXPgusDIgMwQzMEFgPyxS4GXoYZBeeDl/+kfNA7Xvpl+oe6QDsNvNt+Gb8fP2w+FjyHO5j6xDuBPN8993+AAcWCTkKLQrPBrQFagJY/08BvANGBkUJpQtwDtYQoA+TDWsOyhCUETwNdwpHCZEJcgsICnwIhgRgAxIDZgIJAjz9Zvop97T2hPl1+Bz3uve4+ND7Zf1M/Ib99v56AGIC6QM4BEEBwf3S+3X5Gfjn89/tCOzz5jzkoeXj5JvmXeZa5cfkb+IC4LPgDeW17d7+ZA4HGJIrtDnBM5gvqx4EDZ4N+QalBF8GDwXTDDwSlxIlDiQBSPKb5Q7gB9wV26zdZuFa7Jb40gIlB5wCa/1c+iH5U/xyACEFFQxyEM0TzhTvD04NsQaZ/nv8jvcJ9kz48/kQ/w4DTgY8C48Msg/bE6QT9Q+lDAkMaQ0oDoQMJgz6CHkHlQR5/uD6gPbh8ozxe/Gd8h3zsfJQ9F33gPyg/Qr+8wDPAiMFrgYXB9QGjwV1Ae39FvrA84jvRuh038Dd89lv2Cnaid5F5LLodu1G67bpseF/4CvtWgFFICQxAUPlUatBqizPDtf2yfWF7l/uZvFB8xv+SgQPBUcDrfhE6H3fpuAu4x/lAOya+fULBBs9JEwljx67EwQIif9W+8n5IvhC/sADHgPsAbz7lPOo6pnh+96U4TDofvES/NcJuRXrIIsl4ScvLbAt2Sr+INAWLRIMDxwNLwhQAtL8JfXp8RbvmemE5TXiGeFv6YDxsfVB/5YG/QwyEuAWKxn5FhQWtBLHDVALigQU+8nzJ+9q7UvpF+Hv1zDTwM2NxkbK28xs0NncTd2Q5knp3+dc9eH5dQ7hJBc39EcMWm5nEFF3NCUNPd/FzwzLEMbtz3rYeOHf96cFhgdIBqX5Ye6C8L/xOPYBAOMNiSEKNIs+5D3KMv4cXwQX7mXdfNQ30fLVgd9W6HntVu+b8iTyFvI487PzcvrEApcNfhj7IOYqRi/dL3ow+Sx0Jp4ZVw0NBWb96vfW8ZrvY+276WjtAuhE5R7lCdu36q76QgZbGUYiJimGLJotEipKIwgY+gzlBRoATPrW8W7o4t3L1QzSf9F51r3VONHU1hXXvda12a/dp+Qd7nL5hAGpC1cIwgAH/mL6cwIJHJ80l0N6XFZX2TNAFAfio7derIWhIaRsu7zMcu72F3snbC1eKbYWCAwvBWL9h/4QAZUK8h4WL/02yDF7HTED6+URzpK+GLmDvSHIlNq57Nr8pgzEE7ATbRFoCtcGgAaBCHcQThg5IywtqzD3MZ4vmiIYDZf2SuO72FTW2dvg45LtofmLAzEMUw5pCzMFqwBpAOT//wTUCQMMSxCnEd0RGhMSEOAJTQQ9/Qb4LPQ88Izrc+ZL4h/g196r3EDdSN9k3rbduOQH5vPllOk56+zxQPjI9iv75PmV7Mn1BQB6EM8yQkNIUedh40eSHQL38cOwramkpp/OrwzGvuayE0g1mkJ2Qmw09CSYFlgG3fuw+KX2Wf8wDy8WrxGZAvjuO90N0TjH+cSPzPLWC+iY/G0M+xsEIkUhHyA/GDwSLQ9pDoITZxeIG04gkRvnGHYXpxGdBP3w6+W63sLcTuXt7tP5ggeMEqUh5yQSGAIM0/zm8oDyQfJr98sByQfmC4EOMQ8ZCsgH3wWX/RP/4P8J+hD68Pfi8EfunOp65hvppOj35PbqCeyY4CTYx9mI1nbU1+PY6h/xUPxY+V3vIe3r9L8G6CaXQINILF1qbKNQgTANAYbGeqsmlrWNA5vyqyXPwwOZLcFITlJUSNI7QC5JFB3/3/XR6sTwIQSFC6AM/QM377bhT9eezCLKWc502Xnp1PpZDD4bASWhJ+4k4R9vGAATpA6BC8cJiQdMCdQKkQppEPoRIghx+3Xwqedl42joiO8G+bMG0RIGHmIlGB0rDh8DTvfD8dHwpfE9924BAgZ9CicTgxNPEdQPYgdD/Q/48+zC5cXlwOCg3g3mXew873j2Ufbw99L9HPV4723qSdsg1cnVyt+c73f4YPcY7kjlj9sx6wUMVyATPgZT7VbWbLVgWSpHB8jUfJ9alCqO94lApaPK+fMRLPRP2Vb7Vy5O5zN0HJkFcOwZ4Mze++Vy9GH8vfuc+a3z0uzp5knhWN8C5cnqlfGS/8cJQRE8HCgiqSLjIhschRZFE3EJXQEy+0T2GPUQ+wYHYQe5AnMAlfaP9QDz9uuw9Lr50wDVEZEdTiF4GEIN+AT8+m3zmu078Rf3Ivt+CR8RsxXhHHMWCRCzCn75V+o54+Xbftdd2SzcfeJa7yb2cv8CDf0HGQFZATT0ROMR4LTdNNTH0+bZA96G3lHmTvIh8ML8RRT5Ka5FMFQQbFx2oE93Kqn7T7ycoKmPSoNHklyn3cxKBp81LlLNXYBZjkuCNkIbNP555evUodMM4oDwlPliA2QEB//M+zvw5ud95a/jl+kR81L9iwcKETMZdhzlHu4gvhx9GWURjgWi/jX2YPAa85/9yQYECrcK9wcOAsv1se3p7cbl++nW/OAKyBuBI+AhlyRBHFUNaAubAWjwBO8Y7nDtovqxAPsCqAz1CiAE5AOD/qfwoe377tXl4ubq7Uzu9fc6/1UCuAqrA5/3H/KQ5nXXItOO1n/NEND73grfZu2d+9b3e/9tBtEMDSfSPiBJT2P7b+lPbDCjBXPG36bokoSAkY34oK2/EvphLMBNJGG6XiRVdkQ8I/ICJ+a+yrTHP9ZV47b1PgX7CVkOwwwBAdf1o+uV4WPgduYB7Mj1vALZDvcbSCT0J5QpWyWmHJ8PAf9+8k/pBuU37zD9DgSQCRsOhA4BB/r/Rvpg8PjtIu8m9pkIKhNHF0wheB6XFToWywgV+Cvz8ed24kDqGe5g9ugBdgWrClsPcQhrAXr/NPTH7BPuv+ii7Mr2NvYLAIcJuv/q+bD0ZOMy2AXXvtaS2KraAt0m45voG++6/r4EfQYCEFgd9TI+QQ9ZzWgqSqEopAIQyvqtbJ0sjr2ZU6kOxoj6pieWRelW/lZFT3RAWiW5BtzqZtJ8yXTTzOEP818C1wu5EeQPMQbA+6LvuOUk47Lj0Oju8Zz9lgl0FksglSUyKCgmcx0KEGL/d+8Y5TPfO+lz/G8HohGfHB4dthVtC5j+1fAm5yjkgujE+NsIOxVcJcAqiyXvIZIUtAD28TLi1tbW2MjdAOct+HYHXhPHG6AdrhS8CGz+Z/Ew50Tkh+PO6Wf0w/3fCGUI/ABX+7/vs9+4123XVs3FyEbUltYn5c36GP6NCLQQrxGqHUkx9jZnPchVd0zvK34YF+jFuMyttJyzmdmsZbxo3RgM2C4zSX9UTFGNSTs1YxvYAZLmxNRt1MvZ1uNa9S4BYAjqDucKfAFZ+rzuXujB6g/rI+/p+K4CUA/KGRkgOSXXJcAg1xaPCXH6Fu9f6izs0/YYBdIKyg1hEe4LngUXAwv99/WS88L2Uf3+CBEVRxo2HGsYLhKHCN75ZfGT6KndGeMb7E7vc/61CpAQXxs4HkQV8Qx7BPPz2enN5z/jFOrP94/9DwoyECYDXwCG9ujbp9FGzNTAj8D+y0DXV+u0AOAFlhCpGBUUbhq1IX4lSyy9NgxHZT4kIMYG1+DRulmsq6RRpC+yxcg27QwUpDQ/S7RQNlC7QaUk4Qvu8BHbgdcL2hDk+/SwAEcIdw5TDp0E+/lM8aLotuUC5THnLfFc+o8E0BEkGmgfnyE3IHEcuhOVB7761fGV7GvsfvgoBX4J8A2qEMkLAgU9ACv5I/SA8qLypv2GCW4ORRcKHMEW7BEGCcf7OvA35Ljfx+H/5mjzwQDFC3EWphqiGmAYKQxHAQ35iOpV45Lm3+pf9U0BGAU5CHMJoQCe87joC9tLzmDJnMn5zMXUSeGJ8IT+oQ6OHNkbRRioFcUV/R7BJ6M2Mz9KKlIRWvW+0ozErrv4s966wsJ90Vbw2hBhLEw9d0P4QPAzfyNoEFL8hOwU4wviFujY8Db5EgCGBHcCgv5H+971V/JI7kHsDvEq9Sn74gWODjsW3xv1HVEf9B1qEqcDcPkM7uXnI/Iv/4cHWBHkDz0PvhAzBH/83fiN77XwHvlwAHwOvxdtGjgeJhuyEbEGpviq6h7jKd4W3YfnOPJ8+m4MHRg4GnMfuRr+DiUGCvly74Hs2ukg7oz1aPkpAKsEHgGT/bH1veSz2JzRbcWkyWzYAtgD5zv+kPuwBAcXLBCsD7QVew7eD/IdOiefMSE2ayCQCMbxas9rvdK6HLLMuQzRyuamCL8oJTruRSJG0TdcJF8PZ/md5oTcDtrK31nrhvUCA+4PFBMFEikNTAKn+PfuYee+5TLosu0v9yUF1hHHG+ch7CKkH5kYAw3v/kv0E+0+6yz0x/8jB1sNIRAjDkEKpAWuAK/6R/bG9Wn3yf79B4AOSBWkFVANQglAA6z2wPRj8yjuxfEp+L//SwogEh4XZhj6EzwKQwBT+TzyGe//7f3tx/R3+/X+7wLd/f7zW+154+Db9NoL2FLR7td45hDtTvyyDtgLDwn9CDb/swAd/yX+3ArzD3obai1+KPkX6AqO8SDW9MzxxR3Als1B37zwaA3PI/MuGjnfN1IppRlqBxX04OeF4fjfgeWC7dj1tgAFCtMMBAwBCdEBNvpN85Htzuuy69PwtPqHA6UNOxRAF5kXARQpDxoHbP8D+2z2PPbF/YkDvwdhDFgMfgn+BX7/cvqW96fyyfKb9vD6UgLDCI4NHxI7E8gPywwOCjYBX/rE+vX1TPIg+KT9HwGIBqQLXQxkCl0I3QPt/Sj5fvIg74vw5++I8jX2y/Zw+dr6j/n59ebz++/f5b3mZOei4s/mQubQ5ufpiuxp9yL/oQXUCCkKphM9FMgVbiLnIKkVHA4KAX3ueOLf3FfXD9ox4GPm3fcnCeMV+CPDJ8MhKRzmD2UBNvnb7oLnIukD7GDysv3DB64P+xPTE/8O8QcqAP32A/HM7f3qiO0r9Ir5fAGJCDAMjxABEoQP/QxFCUMFygZkCQQKpAuGCp8FygJx/vj4LfjN9JvznfYU+RIBDwjVCwQQsRD/D5kMoAkXB778sPYI98LzDvWT+1cBlQc5DZkRIRTjEtgLkwHc+Svy1erK6GnrCPD79vH+ZQTlByIF2P5v+OXsUeNi3L3VTNaZ2i/fZOs891r5XP9JBEf/Av81A6wCtwLNBsQKFwzcEIgWyhEyDQcFo/KA6HbjSNvt3H3nve0X+f4HgA58FtAarxMyDmEHPfyE95X0RvMh+Pb8rAGsCQgP0BDhEeMO/QcJAMb3DfBj6h3lu+Qi6fHuL/h0AqELXhOLGIIawRmcFrMQFAgTA/v+t/qw+2z7Nfpl/dT/xP/HAhEE6gIWBQAFOARhBn4EAgOJBNsBmf9bAez/Yv3l/goBmwGSArAGmgkzCnUKBQmKBisD3f71/ED77fZ39PvyTPHT8h/1PPbi+bv64/q1+1v60PkR9vfwlO1b6GHjmeaI6HLmpO7l9x75KwG3BiwCogHL/pP4zfUb+Bn6Z/wyA/sJkAp4CP8HfgK8/gb96fcB9qT1GfMs9Ff2v/ho/uIBpASsCTQLxQn0Ca0HdQWDBbkEEATxA2ADUgK8APH+Vf0c/HL6x/gz+c34afgO/Hv/gwEYBkoIKwhBCcMIyQZmB1YH1wWDCesLmgytELIQ/gpeB/0C7Pyw+2z6Rfar+Ib70PlQAKQFawQaCJsLDQgDCZ4LkAVFA1YDt/2x+5r+fP5vAKUFMgczBzAIrgZqBAUCL/ww+Dz16/CO7z7wuO+k8Un0NfTq9o75YPns+l772fiG90D2cPLp8LnyfO+M8GH2ivN69vX8H/oT/fACcQLcBuoL9wdjA/sDZf+v9uj2Z/f/8V3zCPeQ9ab3IPzT/dMBWAfcCIALNw07CkYJyQgeBMABuQEO/pT+NgF5/+H/+P8C/Q39kP3Y/HD95P4V/0D+FwDOACAB6QOQBUkH2AruC/gMzhANEfgQVBLWD2ALnwj5Ao/8pPlo9hP2lvcV+I77v//pAM8FPQiqBDMG6gXAAWAD7QUtBH4EvQXHBEgFzAY9BXEDugGW/OH4o/dk9XTzwPRu9WH1Dfjc+A34mPne+Xr5efvA+7f6B/s1+X/19fMu8Tftl+s96dnnweoy7lTzBfwCA1EI5gyiDTgOWg05BpQBj/5z98Xze/Ge7JjsJu4r8Jr27fvSAJIF9QbTB/AIxgVlAr0AYfze+M330veL+ib+QgBcAxYFuwUVBwQHsAYmBnkC/v0b/L34H/f49nv1Z/Zq+e79EAM8CagPMBTfFc0VyhStEDYKDgUsAIT7CvkE+Av4Ivmj/DgA7QPaB4IIWQgpCNAEFQEV/xn8ZPvL/e/+RAEMBFQEmgalB48GOAeXBJ4ALP2V+SP4pPah9v/3+Pig+5v+dAG/AxoEIgQeAhn+vvsU+Gb0nvL674nuxe5z7/PwjfNg9J71+/cv+Gj59PwA/zgAFQKLANoAjQSAAoX+rP+1+zL1H/ZH9wH3VPmv/Kn9+v1L/jH/Af9Q/Wr9Qf6E/rr/AAJrAwMELQObA7gCrwCGARn/XfuD+wv5+vVw95L1m/JO9Af0w/Ff80X1dfZy+54BpwixELQUuRcNG94XhhXIFYAN1wa2Av/4X/XE9XbyZvOu96f5c/5LBGQHEAskDpQMyQlICCEEZwDV/4/+Qf79AbACtgMLCMcGOAT2A0kA//s5+/b3b/RL9IHzYPNV9xX7a/4DBF8FsQUWCGkH6QUcBaMCFQGM//D8BPui+RL4MPZy97b3S/bz91f4ePfD+S37HPoO+lT5K/j797P32vkD/gkApwLfBeMG+wffB6IFmANbAQL+Z/oC+DX2C/Xz9DX1Ffio+gT7ff/1AuICCQXGBNIB0v/7/XT6QPeS9pL04PMf9p33h/qX/Yr+5/+YAFP/tvzo+kX5Rfcr+PD5FP0cAkgGNgmcC88O3w6VDosPzAsECLwFwQBG/KX6OPhZ9Uf28Ped+BH9BgG+A5sHfAhVCM4HYATHAWYAM/0L/QH/4v+1AfwDpQQ/BPgDgwGA/uL7tff09CHzsfC+8IHxK/P/9cT4kfsd/nIB6wOoBokJrApNCwALbAhxA+P+wfv+9lfzQfOr8r7xXfMa9SP2tvg4+or6afxj/a/8L/5g/9f/3wEJAiIDNQUrBEQEuwTDAdj/1f+n/cP7/fxW+3n5l/kE+Dz43PjB+X77x/wi/sn+5/+XAdABXQNxBGkDRQTbA40DzQSXBEYDTgNYA2IASf7r/Y/6B/cJ9/LzE/H38tbzRvbw+rH8cv9fAZ/+If8zADv9DP3Q/5P/NwE+BqoIxAuTDicNLgt0B4AAEPya+Gb0AfN+8mzyhvSq9kv6G/9KAlwGPQiIBz0HMQUMBKoDrgJVAsYBSwBG/hD+lf0C/VL9UPwX+6r5N/gd96L2nfbT9pP3x/gC+pz7g/0B/2QBwAO8BAIGNAhpCB0IOQiKBcsCHgFm/T78Hf1t+yL8DP7Q/nn+9f8jATb/kv9F/2j92v3T/lv+sQAnA6sDIwajBm0FHQZYBJYBXAEeAIL+Uf4+/7T+h//4AN7/8wAdAl0BuwE+AtIAHADm/3j+if0b/Ur8//wF/vL80v63AGr+kf/HAPr8SPup+fHzXvE18s3uTu4M8jHwUvIO+c/31fruAzED4QKZBw8EpwHQBHABzgIlCRYHVAezCSgEPv8A/Qf3+fJg8/XxkPEj9pz4X/yPAp4EZwcXCiQJ1AflBkgEjwFy//P9zPyp/Lv8NfwK/Rr8E/va+pf6//pw+vv5dPo6+0D8Yf1D/08BsgJuBEUFxAVLBpoGHAb6BL8DsQFB/0v9P/wm+0r6//nP+r37d/16/6sAIQMpBLcDuAOJA9UBggBgAXEAsACFATUA1wB3AKv/+v9L/53+hP6Q/rv9Vv7V/1T/gwCwAecAUQJCAhUBSgEWAKr+P/37+q35pPhj97z3HvhI+Cf6ivuW+6f9IP2L+5T8c/pt+aT6//k5+ZP4MfZw9FHylO4X7gXuH+6c8kH3fflR/n8CTgPEBTYGUgYKCXQJlwuVDg4NVAsnCIEB1vul9j7x4+6B7lXv7PJL9xj8egFhBgUKKgzwDAAMEArmBiwDKQBZ/Zz7Pfta/DX+CwAbAhQDWAOCAt0A9P4X/Aj5j/YF9Tj06vSB99v6Ef+cA1AHIQvwDUsPaRAKENYNJQqwBPX+nvjo82vxlO+p8Uv0/fcS/fUAswWNCH4JXgrhCUMHDAUnAsj9/vtk+nf4gPm5+pP7i/6aANsByQNLA40D3AOGAUgB5/86/QT9j/uL+ub6Ufou+tn6wvpy+0P8vfvL/KT8bfug++T7A/u0+h39EP26+/z9/f3B+jz6tvhs9Un1I/Vz8/P0fvXR8wP3I/cf9iX8ovwi/YoETAURB/UN1g5yEFgU9xAgDAQJ0wAN+Yf13O+b7Dru9u1d8Y33e/vlAZIHqgqBDYcOKQ05C08JggWnAsYAY/7X/Uv9Mv1d/uv+d/8xAKr/i/4r/fj6Qfgm9jj1ZfQd9Y/3lPqd/pgCkgZxCvsMIA+IDy4OlwsXB+sBZvzE93z0F/O58lfzV/VG92j6Pf1f/xACeAPKA8oDGQOTABP/YP6s+2H8Iv2q/OH+l/9Y/z8AzP/+/YP+RPyE+qz8+/l4+iX9mvvq/E3+df6b/kL+//2+/E77vPpf+ib5f/mj+TL5dfoK+8T65vtS/Z78/f3g/qH8+fxH/Pr5kfmb94322PY99Rf10/UN9Uf11vZI9234Zvyz//sCZwmcDEIPFhTdEgQSAhElCR4D6v3W9Rvx1e4e7BLshu/+8pf35/2UAugG0AoNDG0M3wsMCZgGRQQmAe//vv/j/l//2f83/5b/ff/k/XT8VPpg95P0BfI38D7vnPAQ8+D2K/zYAJ8G1gpnDQ8QLBAwD10NLglJBCb/0fkB9XPxPfAG8OzwoPMS9uD4RPwq/tv/3AGSAnYD4QM+A9cCsgIdAoMBfwIhAScAOwEY/v38Gf1b+Vb5hvmJ9z34+vgB+df5w/sr/Bj9i/9h/+8AdwN4AWECygMPAB0AZQAC/aL8ev7//PP8sgBt/xz+qQFs/9f8dv/m+7/5bfsY+KT3Gvlb94P4RPlL91T46fmm+d76kf05/X79HgAQ/6z/+wK+A9QF0Qj6Cj8MOA2PDZEKwAdaBH/+Tvp/9t3xHfCp7wjwoPPc93H7kwB2BFsGKgkFCvIJAwq3CH8G+QSwA30B7wB4ANz+nP75/eX7i/te+jP4ZPcw9iP15vRj9Y32tvjS+/D+cwJ0Bu4IbAukDAgM3QuDCYoF5gGP/e74uPa19Kbzp/Qi9dv2LPmr+13+UAAxAkEDYAMmA9wBLwGDAGD/5P+V/6j/9wDCACABuQEGAVQAGf8P/tH8Avsx+hz5lfh5+cj66vwy/+0BsgM9BCYGlgVEBMkDlADJ/p/80fgu+SH5rPdR+3L91PzzAIECoABBA2MCYf/n/+P9U/sQ+076Kfmr+vz6R/ub/ar86Pvv/Y/7tvmT/Ib5Zfie+0D5MPmT/AX8CP34AfMDEwbLC/QMOw26DqsKigcRBBr+/Pn29QXys/CD8SnyDfXe+c78HgAhBBoFIQbPBhcFDQTLAqYB8gB6AI8ARwDWAAQBuQDvAKf/Rf4h/W/6N/gs91X1lPSH9ez1dPeF+lr9YQAQBJEGLAgJCgAK6AhHCOQF7wJnAFL9Nfvc+Y74Tvgf+cf5nfvG/G/9/f4c/6L/4f/H/7r/W/9x/1H/sf+KAHIBJwK6AhsEJgOpApQCyP52/o/9C/ry+mf7LPmX+2H90PuR/10BYgDdAjIDHAE1AqgBef60/1T/OfyZ/Qb+Lf2X/pv/5QCKAdUCsQP/AnUDEwHv/qX+1/oC+7b6hfcz+k35G/gC/Bn7d/pV/Sf8i/o9/Gn9KfwH/sr/pf05/yH/z/0S/zD/bQHUA2cF3gjFCSQJ5gh9BkYDxQBl/c35jfhj96b3tfgQ+rH80P6YAGACNAPDAhwDtwFwADIAXf9F/6L/jwBeAX4CYQNYA34DtgKXAM3+Tfy0+b73Wvba9ej2qPgD+23+PQFeBCEGTQcYCM0HqwfQBXsE/AJeAN3/UP5z/T/+Z/1M/Vf9H/26/BP9I/2i/J79mP0Z/hT/IP9HAIIAuQCEAQkBJgHpAEUAAgBV/1L/9/6r/ob/Wf53/qj+uPwZ/VP85fu0/HD9k/7T/toATwFLAQAEDAOxAr8D8ACb/4L+YfyJ++/6n/x//R/+SQFVAQ0BFgJOANv+yv2M+2L6pPlQ+dX55Pp4/Av+Tv/M/8X/1/5d/RH8F/pk+P33aPbI9lT47/dd+jL8avwQAKgCBQSUB1QJUQrICkcKjAjgBa8DOP8y/NP5QfdK9zL3zvfv+Qj7IvwJ/nn+rv5j/+H+Lv6d/uf+sv7H//4ARQGDAiIDvQKOAt0BdwDu/qf91fuc+tX5DflS+U75KPqF+2n8Fv5r/+QAEgIuA/4D3AMvBB8ENAOXAvwBeQDj/4H/8v01/QT9Afze+/T7Qfsz+6r7Cvv++hX8dvuc/Hr9Hv0G/4f/3P+ZAVoCtAJIA2cDkQJ1ASoBcv+G/Sb+afyk+9b92vtu/FP+i/x2/U/+fvwm/P/9KPwJ/IL/YP0Z/5cCdgCQAwUFlwLvBO8D8ABZASD/XvyA+1v6uPjG+C/6Vfkb/Eb+2f2XACYAQ//K/zj+Qf01/Bb7l/pB+jj73PrJ+8H9rfx2/Vr+zfxp/ff+rf7w/9ICUgPxBFEHaQZmBnkF3wJcAQb/pfwJ+zv6jvl0+Wr69/rL+xH9ff2x/SX+//1u/bT9mP3S/dP+U//BAMQBgQKYA+EDnwMqAzwChQDi/oz93/sc+7/6TPpD+z78Af1i/pX/RQBOAYwBVgHJAVgB2QD7AH0AVAC/AKAAjwDdAL4A9/+z/yL/u/3R/Nr7S/qh+Ub5IfkL+gP7b/xz/r7/CAGvAvAChQPyA6ICvgGSAX3/1P6y/w7/PQBgAdcAaAEiAXD+Lv4P/FP5QvmO9x/3efgn+mP7Vf46AT0CAQWyBp4FzwbGBZoCagKN/z39FP25+vr6n/tP+iL8xvxf/ND99v3r/NX8ovzd+yD8t/xY/Sb+L/+D/zQAhgBh/9n++/0Y/Pj7r/uK+v/6Z/sd+177DP02/Tr+2QDSACQCwANHAqMC1gFx/2r/uP1u/Fb84/v6+1T8Vv2X/cT9f/6D/S/9JP3U+/f7tfuj+4z8PP1e/qv/pAA+Ac8BJQK9ATMB1gCY/8b+ev6G/U39c/0b/an9A/7z/Z3+ZP5n/uH+g/4v/uz+2P5N/lv/Ef81/wgAuP8+AG0AHwA2AOv/av85/5r+9f1R/dr8pPxs/MP8gPxm/P78C/01/Vj+Cv8///v/u/9y/4r/nv67/iv/d/4+/1n/kP4AAKj/L/9qAHT+0v3q/V77+vsh/NP6ZfwO/Sv96/4bAGoAtQFUApoBuQECAVr/8P5w/vX8O/3C/LH7tP07/aj8Q/+Z/T39Nf9G/Br8OP1W+0/7SP20/cT8KgCA/zT9WwFZ/aD7nf7/+QP7L/yO+d77efyr+8D9qP50/hcA+gGcARkD4AOrAaACIwGn/3QAa/5R/o3+B/44/lX++f44/hn+b/7s/L78Av0n/IH8UP1Y/V3++v9vAFABNgLlAT4CeQKWAYkBFgHK/4j//f6P/tv+w/6y/gv/Dv9q/pv+av5Y/cL9dv0Z/fP9Sv5D//j/fgAyAXwBHQECAfMA5/82AK3/pf5a/53+g/7n/kT+c/79/Tj+i/2m/UT+Uf1T/kz9U/2l/mb9Wv4a/yP+3f+sAK//cwFpAbT/AwD3/lH9M/2y/DL8Sv28/Wz+KwDS/zoAdAEmANX/OACT/pr+Cv9y/gP/QP97/8//uv/f/0//ff7M/gz+ZP1i/rb94f0b/8H95v7i/5L+MgA4/1P+oP/6/Z39uv5v/WX9bv4x/Zj9JP5e/a79if2d/Hv96PwW/E395Py3/en+7f9IARwCMgIsApEBjABeAF3/5f5n/hP+vv7H/oz+6P6+/hr+1P2V/c38OP3L/GT8af0m/YD+9f6S/+0A1QARAS0B6QCwAEoAj/94/xn/nf7C/gT/ef69/tX+Gv5l/s79Lf04/Yf8+/yo/XX9gf7P/tX+yv+t/wAAqQAkAAYAbQBCAMr/jQCi/+H+kv/x/az9z/23/Ln8k/w7/Cf9H/1l/UP+nf71/hX///+e/ykATgBc/0IAuv+C/wsAr//R/+f/bf/m/jz/2v7t/Uz+df3i/Fj9jfxy/d/91P10/vD9xv4x/93+wP8aALb/iQA0AOf/uQD3/47/dv/W/ur+xf6O/RP+Ef5g/YL+Pv5e/eL+n/2q/X3/oP3p/sT9hf3h/vH9Qf8Z/xv/3v5A/0n/If/e/5D+pP7M/T/9+v3V/Cf9o/1G/XH95/4v/jz/YADE/W8Awv8b/h4Bff/I/v0AAP/r/h8B6P0P/zUAiPwb/1D/3vzP/+D+Rv2d/1D+6P4qAKz+FQDBABMACgG2AM3/5QAwAPD+kP92/2T+Ev+7/pj+XQAu//j/9v9R/3L/Of59/3L/2f9fABMAwgB3ABcAQQCT/9T+Of+p/ob+Of49/oj+if6n/2D/6v/p/7L/bAC//0oAIQCx/6sA9/9f/4IAtv+q/mr/x/7p/iD/vP7K/jz+rf5//er9vv5k/br+c/77/r3/bP6d/97/Yv+T/6//rP8UAPH/s/+3/w7/Ef9v/4r/of4t/8n+b/74/sP+GP8B/y3/T/48/63+cP3Y/iH+1P0w/27/sf6k//H+4/5YAKD++f/k/0L/yABA/wn/of5Y/jb+FP4U/vH9Of9Q/mb+TP+T/c3+HP+j/bv+P/7C/fz+8/4t/r//ov9F/y//5/7X/jn+8/56/WD+Fv/o/cT+K/7E/uL+3P5I/3f+XwDv/6j/bv8K/zH/6f76/kD+wP5X/koADP9z/kT/Pv7//hD/af6v/g//DP54/vP+ef/F/tj/Y/8n//z/gv6e/2X/ff6k/nP/b//q/uP+Zf/H/gP+pv8//8v+wv5k/nn/Mv/y/sz+2v19/oz+Lv7R/qz+fv5j/tX9rv+C/q78Rv+3/uP9Cv6L/jX+uf4+/i/+dP/V/nv/J/5z/8P+8f4B/8f+8f4O/Tf/2v2v/v7+6v54/0f/IABt/oT/IwDQ/T3//v/J/WgAIP8u/w8AI/70/9j+4f5Q/5j+tP4i/9T+xv62/1j+Xv+e/8L9Vv98/k3/DAAK/mL/ef6V/70A1v3o/6r+DP4aANH9Zf/o/vP9Nf4p/9z9w/7lAN391f8B/0L+JQAcADL+W/6K/6/8iv6n/3b+m//P/jv/ov+7/p7/dwAw/0//Nf+h/uAAUv/j/zIA1f7d/wP/XACY/sr9/P5u/gj/eP/x/lj+agDK/lj/tQCR/3wAev95/rr/sgF3/zz/uwBq/8L9Sv8tAuD+qv7//wj/Wf/T/Q0A6v47/QAAS/4v/hcAuv0k/n4Bef2C/2z/E/62Ae/+uv+8/3EAsP3h/XP/8f2RAAj9z/zUAL8Azf12/2L/9f2aAGP8C//U/4D9UgH6/SL/2P9H/6P+Iv/j/tv+wQAU/eT/zgC5/kf+Uf+o/4P/H/7F/TYC0QCA/cz/D//Y/IgAWP03/8EB/vyLAab9I/4YAqb8FACyANr9Jv4T/eT+jP/h/U0BTP+HAVn7F/tBBGf6GABr/UH64AOd/Sb+RP8b/qr/Mvv7/fgAuv/9+5v9wwBC/AAAswAs/zz9if6gApX7Nv7hAJr8Sf31/V8A4PzFAA4ASP2KAmL8gv4GAl/8DgC6/rD6VQJp/iv/zQCR++MAv/5E+vMDE/5K93MGAvzQ/XUD0vnsAn38L/5aAt/+tP79+78Cxf3K/cj+gv3j/iH+0wT3+mn9YAFT+tz9tv0AAST8i/6vAw36Pv++AyL7rP2WAaYDb/rL/KIDYPit/Wz+mQI1/z/7xf/MAZz+kv8t/T3+uQOx980ENPovAmEEm/V8B3v93/hHAPkAfP2m/9ABlfv7+roGMwC29/YFiwF79aoCCAIZ/c0E2vf//hQG8fdQA2AAwP5T/Cj5xA4q8nj99QbY+FT/JfbgC37/DPn2+9IE4wAK+c4H3/aQ/8oDNvmoA+r/t/2/BB74cv1lAxABW/sf/noIePXM+swHTAGXAfP4TwGcBr34svbVBFMFz/bCASv9UQZR+W/90AQQ904Iy/zyAgj9HwLm+nH9Dwuu9HYEwgNI9xsDqvxYAfv/xvpGCTL5zQXz/Dv89Abl8RQI4vzS9rYKMvqcAbYAIv1jA7Tzuwri/PP8nAPC+4n+7f0yAz316w4Q8iECfAfy8vYD9QBAAUH6iwWx8s4Iv/2s/6r8dftQDpb0xPleBN0CZ/YdDFTxdf4iCEX2gQJ6/YQBZ/7d/ccA+gGs9OoKOvRpBQYE1PJJDCPyfAVCAV/48QRVAeP33wOV+AEHnfjZ/yMQUeQnDugCo/KkAVQDZ/8z+fDyihCs/vrvYhJU8bgBGgPM8y8BqwnF8u7+LgSr/K0BsvGsEyP0DPjlCCL0mwtu+R77fAW//KX4gwPGAA/3/gp99c0D0/+u8iAJxgCP+cr9owSi8rMIf/kd/KsDcv+sB6b0oPhzBAcCSvAFDnb7TPwrB9nymQWt/6XwFAmPANb4WgA8+qULpvOSBO39BPrKBU7y1QhQ+Wr7zAuL71P8RRaI6MQFqgQZ9CQNtN/6GXP68eqSEoD2lAWf7qINEf8p7kwKGv5TBjz0APwqDC/1SvcnB/ECLPSzCdH77/jgDhPpEAs8ANT0jAQJ9aUGIflkDfD0rAPX+Sr1YQ1K8mgKBvOFDif4EfS8ECjwKAPkAevzcghe/Xr3zRCs9EL8x/6aBcf+e/bLAmoBngJF8gIOePr37okS+vGXA2wFwvHHE2HtxATA/o/7dQOh+GoG9/BTCkH7uAUf83QOlPx27ToY3ex4B4D+VgES/W78/f+s/kP7LfubF/3pe//0CSLyMAQt/Db8Fg6G8sMC7wNZ8+sO4+p9EmP7bvfJB973DgYG880RUPLLAKoHCfTP/4kDzP5//S/+/PyOCLDxugYVB57t4Ql2/P33mw8d5WQS/wO86kEVMfgc8uQJjQiQ5oMdY/LZ7r8YDeb6CKj/Wf4bAhP91QJo794NZvxv9TMQzvQxBhD0/vx2DYjy/ARWBgH73PM1DWT4ovbnCon51P1x/eUAxQEN+Nb/wwTR9uIFD/6g+y37lgAZEVzpLAwJA8vybwiL8HASdffF87wMRvfM+rYMXvQu/78HP/HiCET4+gUd+yHyHBU/9MPyXBiD6ZEHRw0e6gwTje3jAWEGzOopF4X8n+QtKEfqAPC+GxrjAhId8mkFtwKA7KIUDPg293QMzPyD7zwQcPmZ/Ir9kQAoBA73YAGgAdD7EP8i/nsHtvmv8xgK7/Z0DLztaQptANzySgfN+oAPzOjGCZv8tAAxAmj1VgUq+CMIuvV2/XEK3/F4/GgU8+kaAogI8e56Byb5EwSqAvzsJgpcB7Lr8hR+7vL5phPh5hsGHQbJ7D0EBQ2x8lEFXf4X+CEAxvkV+ZIN5Pdg+HAQIfaHAbfrrBP99cH8LwW/7kYfdtfeGK39Mu4rDL/0Wwh6988HPPkBAWbuyA+M+db/AwAt8jEP1/N1AKQIkPSI/CsK7fNnB+bynwSW8h8PLgWg52kWjfZ+9+8Effs/9VUNMPSQCNL49P8sA071RAcO95ALZ/Xw/E70QRGIAhTvfgtx++4DP++VDyT1ywVMAwjuVh0N4cQIaQGv7xsWd+7vA9kOdN7NEi0GgeE0HWT14Os5Gjj2BPD8H+rnaP2iBxQBUP3F75UVAO9VCuv5p/7GB37v5ATTBoL1DPzXCQT4tgun8XEF4APd7RIQs/T7A6j6YvxjCUHvGwxZ/lb6fP/H/s33Vwg9ARjtoxb17IQElP4R/koDfe1FGqTsDv8KDZTwBwix+1D3MA7T7OQI0AZl9HQKTvLQAQv/qPxTAG0JDu0rB0kJFu5sETr0Xfh5BiT4SQZT/9QApwSw7pMEjgXA8wsKcvzQ6dAfsvd17skP9vnR+C/0ihVO9b4AbwKq+yL/bfXyDkntoQ31+MT/Rg2P52gROO39CmP5rvUDHBDkKQmF+HX+uAFd+d8KrP438jsGXwEJ9bIKbOVjIS/1Te6QFLPvcQGC/R0IdvFLEwPzkPhVE8PkNwkM/qACfgFJ94AD2fj0BhLuiQptCATlQR6f8F74aAvy8LQMmuitD/oCZ+Z5HBr6zPPQBFz9vPp+/VoCtP41BqjybwvV/P/wmA7L6Q4MzPjwBGIFY/UHCx3sFAq3/dj7kvv3AP7/6P38A9P5FgEeAzTvlAQiCm70lgi17g8CcAXF9i0Gvv9u9sUJW/WfBPb6sPvuDCru6wyQ8REAqP/0Ajf6ggwB93/0PhgP2sMPtwCH+p31Cw4bDujcQBDTAKv0e/7XDbTxhQfU7N4AVxdN344YLO83AfUHavZy/xn/mP0O88ASZvWVCqPpZAKlENjnJRGX83cJGgMe8dIMX/pq8NAJ3/Q1AbQQifP/DBLzXvgQAgwGNu5SEYz9oOvQHsLcZBdW7OEMdAm15C0VwubuECr1AgqD+Tr7AgEZ+vsL//D+CVL53wZsACf0qgBKBczxGARyBsn3mgnS7/wBcwJQATL/ofg9A2UEPu61DIoHXvDSDpbpqQh8/S/zDw8R+qT+8gEkATL4wfUiCcABXf6n/I33Bwk7+O70SwlTB4jl2xbV9nT6Zh2c1vcUA/xZ9QYD3fF6DiL+CwSy/cUEVPWp95j/4v87CQH4WAWIAcr2PgEN+WX7JhCH7yQDMQhg7XwNx/iX/eACkPquA+/6XgEtA3j+kPEOD0f5S+ynHHDqNQWGAEb96Q7v54gKiPvn+1n/FAX//R71nwn47jYJqwMu+JgN++39BdD/MfGjBZUPLeg+A2YJhefKGvvmXx4J+6TlpBIv69gHqf5q/hIACw+m7T4B6gPi+Uv8G/5rAscElvzF7iEaxugbAigG4fpZAGn8Lf9n+wwOGek/CEP8NPf0CUYAwQSj8CkKw/TW+y8Q4uDSGsb+JOn2GdPq/vn+BhwDMvbcBUIG0evIC8DvnPwvFCHvtwN7CTvvlPU6FSD39PEpFsDncA+j8tvtEBk27NsM6/xk/oX4XAIhA9rx7Acd+ncCX/o5BFUAC+tLDa/4EPi1FEnwgf+3BL74/gCh9+UFtPts9+gHf/INFeLyY/dyBYTpHiBt43QLVwtN6LAPgu4gBBT/MvYNCN8A1vYJB0n89/H2Ecrzr/d4E3vs4ACJDOntrwc5AjjkZiHi8wLtthli58AG6fpOCazxYQOMBODvIg00+b8MZuadEeD4BvhdCGj2aAp671UM+fcjAXcAz/x3CA/r+wvN/RTvwh5Z5D8KfwGg6lQaHeVUEWj7YPSDBu39QgP7+RAD7vxQ+SIMqvlC9+oO7OcpFHr3D/8vBsvxtg796YEQffc5+O8QSPVTAZ//s/f0/RgMHPOWACwHrOwsBMwK6P0a9cIR5OpV/m0JKe14EDH04Qk/83EFRgbr6YEXHvLu/ugC0PP5FZflSwrLDRHpBgboBzL/zfaSChbzWwW+AJHzMgdyAxXwgwplAD0CPfq8+vQQyepZCO3uFxI5/OrzLwVfA24DbPDcGcHnzQXBBk3oMwvbBu36g/7rCrf5fvM8DYfyqwJ+CTLyXRBU6poNwQRW8NQL1/ZgBd34dgZS+R/8wg0A8foLzvhe/yUKKeZtEej6/Pz9CBHtKhJi9/jzkRHV90oA/fsVAbn9sQAd/kH5vxAi+K73MPq/EC7ueAPqBkjyfRHS6DkOkgML7CcOkfZg8NIXSPaq/R0HceifGarwxPnSDfbqNhPc81wCWQef7hYGgPvL/FEC8P96/vQH6PJN/gz5OwQW+Ej4SyUN4MH4qxgK7BH/4wqz7YoOQewL92cgBeaWCQAAzfUNBzz3Cf0dCJ/uYfz/D671fhJ850j8HRX82jwWKv6sAtb+Cfl5BJD3KQMw7zQSjuRiEYcJm/fhAwb47fXMBGT+vvfREATo0h4l3RwQmvex97oa7tzYHPjmEQq8/pf4aw3K6GAM9wCI9ssChPepBDz9oP8/Bwr5g/pIALP5IgNvBHPuIxMh9Wf03QsO878HAv7YAlr8kQUj/oj6gwOo6XARDvbE/L0RbOzGCX39+PpiAunuYgh7AYT+xv9h+AMFi/wa+ET9SRMW5Vz+ARhz6WsYVOiTBosLkOULD7jrVA/H7LoNvAfg79YQcehcBU/sGBnl94P+6w3N6SIVst6cFL3/ReWiHXz0nf3T/w37NgI5/nf+EvwuCljyT/osFFHgmgplCFfnEh9j8Dr2gQ4E67kK8gOa7CIe2esm8TQMffuRA6X3RwJc+2AMwOwTE9zpwAHyAh7sLCLJ6WsIS/VnAiX66ARx+PgNUACG6CkcauBNC3ECKvKJD7n7NPZnCg729/3wAH/2QA5X91kE6vif+9/+Dv0gBA4JZv35/LP5HfW2CuDpXwsxAQz/QgVA+jgDlvRHC4Tmqw0EBnvjsCCR8qP2OQvt+DP6oftAAYTwFxPI+MP9LAvY62YDwviqBu4HHe9ICf79OfqiAh/snRXQ8oABd/rP9sEST+ZoFcP2A/0rALj1kAos9v/4lgox/mP3ExBE5WUCYxBV5uwJRAUY/Nf7rPxqBX3xKQZNARn/mf7L7PYNmQEg6hoJUgLf77kOEf3H8rcZO+PHA3oLseZSDLnxfACFAgIJCO0sD775s+5tEwHuDQ4o7msHsfrt+SgOfuy5A38Gf/ad+AQK4fag/2sGA/hW/uX2pgXk9479VQf//CD+sfsDBMPzcAYp8m4D+f9a954NdPFoCIX0qwxM+Nf3hv9T8kcPgeSvGrn25PsXDL3k1Qw1/Ib2CvliHeTnJgCEBX/xhwep8/kWF+o7CMD1eP0QDW7vDAvg9BUEKfrU+cwIvvcU+yMJqO9UEHT81urBEAHxdvpJCVr66wAXCFDxzgry+Rn2a/8Y8K3+owr1CIb/jfcUARP8i+yjFi7s8wSzA/ry1x5v5Ir+UAVp8ZYFbQGgAXIAZgRC9xQDFfMK9gkUFPQvBZjvHQWTCYnrnQyI+kMEjfP1AoD6KwUL/tH54xG257sNafoc+231LA3Y8Jb0th3y6EoRIfDEAFwADvsrA0v/B/6P9XITr+XHEV8HyeewCnb2yAWFAez6/AAM/bMGXfKw/BIP6u4g/54DjPpa/7X76wLVAET6QfTyEjf26f4uCAj1pQah7vUOeAFJ8D4HOAhx9bj+UQcr8YcEc/yx+XgAGQky/yP90QSX6VYIlQjL+LsA0gErAJfytwaf/tb+FPnB/pUE4Pos+vcDHQzZ7vUGgvGHBg0FMfjHCyjvTw8q7gEEQwc08iYLc/YSCKH4tPoEDxT2uPHFB0MDSfhmBDH+0/hZ/iX/Z/9ABgH8SfpIAQX/xP1+Az0FdfLfBM/87fWGC6f7qPrcBdPuywygBc7xJgYr/CEAIPNNA7r2RwMUBKT+o/vFBI/6afN9E+nqtQ0c8kQAmQsJ5CMUevpV+y0H7feXAHoD8vth+0H7jfJfABgEcgQg/sTtzwrUAXvz4gks/yz7Fv0Z+Z0Jdfq+7ocNPPmM/gX/1wDSAtLyrQe28KwICvtV+64GTPhhA6L7ogXf9OgGBPf+/Ov/j++tEP4D6/bCBNL7gvadBcL3tfmzDXr+t/KRCsz2cvuNCJ/z7PuDAC7+/gV2BbP1Ev2OAAcAofwY/RYC9Pl8/RUM7PZ8/A8FgPicAqbsERGqAH7zMwqY7u0EtP7aAZX+P/0E9iz7pg3t90/75wbTA2n0+gUi+1v4/gFe+uIJovh9/CIHefjO/PT7W/8XCHn9mgF2/sf6rwIH+GMExAHB9VkHIf3//cADjPzTAvb3DPsdBMz+RP2rBW/+2fffAPr5bP5+ATn6jgBOBs/94Pz4/poByv1l+xgCsf8mAXL9tgFUAq74OP9PAEH+JfjM+aUDpAAHBJIC6vyV+SH+Wf24/0sArf2B/yICwwJC/OACLfv3+qf9Df7a/TQA2ABT/Tv+Nvr0/3j6FwCtAFH8awZz/t77xv4P+9z+FwKi/1L+fPoo/p4Io/qXAeMBnfd8/lr5N/8WAQ4DdPokBMP9iPvYBPf68wNX+HH/7gED/h4Bof2tAOP8zPuyAzb/Gf2o/+P6yAPG/HP67wTZ+LD8xAQq9qQEJwSO/I0DZf9r+yT9zf8Y/C3+v/uZ/GoA5QNQ/RcDevvN+JYDZfazAXIDs/yqAND/JwDf/x0A5v8XAOz/EQDy/wsA+P8FAP3/AAABAP7/AwD8/wQA+/8EAPz/BAD9/wIA/v8BAP//AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "generate_samples(\n",
    "    text=WAKEWORD,\n",
    "    output_dir=\"./data/samples\",\n",
    "    max_samples=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    model=\"piper-sample-generator/models/de_DE-mls-medium.pt\",\n",
    "    slerp_weights=[0.5],\n",
    "    length_scales=[1.0, 0.75, 1.25, 1.4],\n",
    "    noise_scales=[0.333],\n",
    "    noise_scale_ws=[0.333],\n",
    "    min_phoneme_count=80,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "Audio(\"./data/samples/0.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b5e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Loading piper-sample-generator/models/de_DE-mls-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 1/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 2/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 3/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 4/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 5/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 6/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 7/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 8/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 9/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 10/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 11/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 12/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 13/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 14/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 15/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 16/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 17/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 18/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 19/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 20/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 21/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 22/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 23/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 24/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 25/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 26/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 27/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 28/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 29/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 30/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 31/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 32/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 33/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 34/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 35/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 36/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 37/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 38/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 39/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 40/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 41/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 42/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 43/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 44/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 45/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 46/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 47/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 48/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 49/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 50/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 51/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 52/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 53/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 54/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 55/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 56/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 57/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 58/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 59/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 60/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 61/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 62/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 63/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 64/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 65/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 66/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 67/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 68/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 69/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 70/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 71/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 72/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 73/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 74/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 75/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 76/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 77/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 78/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 79/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 80/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 81/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 82/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 83/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 84/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 85/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 86/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 87/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 88/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 89/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 90/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 91/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 92/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 93/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 94/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 95/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 96/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 97/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 98/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 99/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 100/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 101/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 102/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 103/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 104/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 105/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 106/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 107/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 108/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 109/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 110/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 111/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 112/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 113/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 114/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 115/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 116/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 117/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 118/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 119/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 120/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 121/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 122/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 123/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 124/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 125/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 126/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 127/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 128/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 129/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 130/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 131/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 132/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 133/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 134/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 135/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 136/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 137/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 138/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 139/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 140/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 141/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 142/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 143/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 144/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 145/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 146/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 147/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 148/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 149/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 150/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 151/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 152/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 153/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 154/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 155/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 156/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 157/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 158/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 159/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 160/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 161/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 162/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 163/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 164/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 165/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 166/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 167/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 168/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 169/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 170/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 171/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 172/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 173/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 174/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 175/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 176/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 177/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 178/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 179/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 180/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 181/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 182/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 183/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 184/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 185/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 186/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 187/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 188/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 189/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 190/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 191/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 192/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 193/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 194/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 195/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 196/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 197/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 198/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 199/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 200/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 201/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 202/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 203/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 204/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 205/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 206/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 207/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 208/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 209/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 210/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 211/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 212/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 213/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 214/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 215/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 216/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 217/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 218/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 219/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 220/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 221/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 222/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 223/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 224/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 225/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 226/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 227/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 228/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 229/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 230/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 231/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 232/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 233/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 234/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 235/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 236/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 237/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 238/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 239/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 240/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 241/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 242/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 243/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 244/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 245/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 246/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 247/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 248/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 249/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 250/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 251/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 252/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 253/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 254/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 255/256 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme samples shape: torch.Size([16, 1, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:generate_samples:Batch 256/256 complete\n",
      "INFO:generate_samples:Done\n"
     ]
    }
   ],
   "source": [
    "generate_samples(\n",
    "    text=WAKEWORD,\n",
    "    output_dir=\"./data/samples\",\n",
    "    max_samples=SAMPLE_COUNT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    model=\"piper-sample-generator/models/de_DE-mls-medium.pt\",\n",
    "    slerp_weights=[0.5],\n",
    "    length_scales=[1.0, 0.75, 1.25, 1.4],\n",
    "    noise_scales=[0.333],\n",
    "    noise_scale_ws=[0.333],\n",
    "    min_phoneme_count=80\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d11ad",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff337d",
   "metadata": {},
   "source": [
    "### MIT RIR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"./data/mit_rirs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
    "    # Save clips to 16-bit PCM wav files\n",
    "    for row in tqdm(rir_dataset):\n",
    "        name = row['audio']['path'].split('/')[-1]\n",
    "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96070594",
   "metadata": {},
   "source": [
    "### AudioSet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AudioSet Dataset (https://research.google.com/audioset/dataset/index.html)\n",
    "\n",
    "if not os.path.exists(\"data/audioset\"):\n",
    "    os.mkdir(\"data/audioset\")\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        fname = f\"bal_train0{i}.tar\"\n",
    "        out_dir = f\"audioset/{fname}\"\n",
    "        link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
    "        !wget -O {out_dir} {link}\n",
    "        !cd audioset && tar -xf bal_train0*.tar\n",
    "\n",
    "    output_dir = \"./data/audioset_16k\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    # Save clips to 16-bit PCM wav files\n",
    "    audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"data/audioset/audio\").glob(\"**/*.flac\")]})\n",
    "    audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
    "    for row in tqdm(audioset_dataset):\n",
    "        name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
    "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59cd0b",
   "metadata": {},
   "source": [
    "### fma_small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./data/fma_16k\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# iterate over each subdirectory in the fma_small directory\n",
    "if not os.path.exists(\"./data/fma_small\"):\n",
    "    !wget -O fma_small.zip https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
    "    !unzip fma_small.zip -d fma_small/\n",
    "\n",
    "# Save clips to 16-bit PCM wav files\n",
    "fma_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for dir in os.listdir(\"data/fma_small\") for i in Path(f\"data/fma_small/{dir}\").glob(\"**/**/*.mp3\")]})\n",
    "fma_dataset = fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
    "\n",
    "for row in tqdm(fma_dataset):\n",
    "    name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
    "    if not os.path.exists(os.path.join(output_dir, name)):\n",
    "        # Convert to 16-bit PCM wav format\n",
    "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f86382",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up the augmentations.\n",
    "# To improve your model, experiment with these settings and use more sources of\n",
    "# background clips.\n",
    "\n",
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
    "\n",
    "clips = Clips(input_directory='data/samples',\n",
    "              file_pattern='*.wav',\n",
    "              max_clip_duration_s=None,\n",
    "              remove_silence=False,\n",
    "              random_split_seed=10,\n",
    "              split_count=0.1,\n",
    "              )\n",
    "augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                         augmentation_probabilities = {\n",
    "                                \"SevenBandParametricEQ\": 0.1,\n",
    "                                \"TanhDistortion\": 0.1,\n",
    "                                \"PitchShift\": 0.1,\n",
    "                                \"BandStopFilter\": 0.1,\n",
    "                                \"AddColorNoise\": 0.1,\n",
    "                                \"AddBackgroundNoise\": 0.75,\n",
    "                                \"Gain\": 1.0,\n",
    "                                \"RIR\": 0.5,\n",
    "                            },\n",
    "                         impulse_paths = ['data/mit_rirs'],\n",
    "                         background_paths = ['data/fma_16k', 'data/audioset_16k'],\n",
    "                         background_min_snr_db = -5,\n",
    "                         background_max_snr_db = 10,\n",
    "                         min_jitter_s = 0.195,\n",
    "                         max_jitter_s = 0.205,\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Augment a random clip and play it back to verify it works well\n",
    "\n",
    "from IPython.display import Audio\n",
    "from microwakeword.audio.audio_utils import save_clip\n",
    "\n",
    "random_clip = clips.get_random_clip()\n",
    "augmented_clip = augmenter.augment_clip(random_clip)\n",
    "save_clip(augmented_clip, 'augmented_clip.wav')\n",
    "\n",
    "Audio(\"augmented_clip.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b835d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment samples and save the training, validation, and testing sets.\n",
    "# Validating and testing samples generated the same way can make the model\n",
    "# benchmark better than it performs in real-word use. Use real samples or TTS\n",
    "# samples generated with a different TTS engine to potentially get more accurate\n",
    "# benchmarks.\n",
    "\n",
    "import os\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "\n",
    "output_dir = 'data/augmented_features'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "splits = [\"training\", \"validation\", \"testing\"]\n",
    "for split in splits:\n",
    "  out_dir = os.path.join(output_dir, split)\n",
    "  if not os.path.exists(out_dir):\n",
    "      os.mkdir(out_dir)\n",
    "\n",
    "\n",
    "  split_name = \"train\"\n",
    "  repetition = 2\n",
    "\n",
    "  spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                     augmenter=augmenter,\n",
    "                                     slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
    "                                     step_ms=10,\n",
    "                                     )\n",
    "  if split == \"validation\":\n",
    "    split_name = \"validation\"\n",
    "    repetition = 1\n",
    "  elif split == \"testing\":\n",
    "    split_name = \"test\"\n",
    "    repetition = 1\n",
    "    spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                     augmenter=augmenter,\n",
    "                                     slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
    "                                     step_ms=10,\n",
    "                                     )\n",
    "\n",
    "  RaggedMmap.from_generator(\n",
    "      out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
    "      sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
    "      batch_size=7,\n",
    "      verbose=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads pre-generated spectrogram features (made for microWakeWord in\n",
    "# particular) for various negative datasets. This can be slow!\n",
    "\n",
    "output_dir = './data/negative_datasets'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
    "    filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
    "    for fname in filenames:\n",
    "        link = link_root + fname\n",
    "\n",
    "        zip_path = f\"data/negative_datasets/{fname}\"\n",
    "        !wget -O {zip_path} {link}\n",
    "        !unzip -q {zip_path} -d {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129e8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "# These hyperparamters can make a huge different in model quality.\n",
    "# Experiment with sampling and penalty weights and increasing the number of\n",
    "# training steps.\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config[\"window_step_ms\"] = 10\n",
    "\n",
    "config[\"train_dir\"] = (\n",
    "    f\"data/trained_models/{WAKEWORD.replace(',', '')}\"  # Directory where the trained model will be saved\n",
    ")\n",
    "\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config[\"features\"] = [\n",
    "    {\n",
    "        \"features_dir\": \"data/augmented_features\",\n",
    "        \"sampling_weight\": 2.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": True,\n",
    "        \"truncation_strategy\": \"truncate_start\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"data/negative_datasets/speech\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"data/negative_datasets/dinner_party\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"data/negative_datasets/no_speech\",\n",
    "        \"sampling_weight\": 5.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    { # Only used for validation and testing\n",
    "        \"features_dir\": \"data/negative_datasets/dinner_party_eval\",\n",
    "        \"sampling_weight\": 0.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"split\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config[\"training_steps\"] = [100000]  # Number of training steps for each training iteration - list that corresponds to training steps\n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]\n",
    "config[\"negative_class_weight\"] = [20]\n",
    "\n",
    "config[\"learning_rates\"] = [\n",
    "    0.001,\n",
    "]  # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config[\"batch_size\"] = BATCH_SIZE\n",
    "\n",
    "config[\"time_mask_max_size\"] = [\n",
    "    0\n",
    "]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"time_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"freq_mask_max_size\"] = [\n",
    "    0\n",
    "]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"freq_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
    "\n",
    "config[\"eval_step_interval\"] = (\n",
    "    2500  # Test the validation sets after every this many steps\n",
    ")\n",
    "config[\"clip_duration_ms\"] = (\n",
    "    1500  # Maximum length of wake word that the streaming model will accept\n",
    ")\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config[\"target_minimization\"] = 0.9\n",
    "config[\"minimization_metric\"] = None  # Set to None to disable\n",
    "\n",
    "config[\"maximization_metric\"] = \"average_viable_recall\"\n",
    "\n",
    "with open(os.path.join(\"training_parameters.yaml\"), \"w\") as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24527804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a model. When finished, it will quantize and convert the model to a\n",
    "# streaming version suitable for on-device detection.\n",
    "# It will resume if stopped, but it will start over at the configured training\n",
    "# steps in the yaml file.\n",
    "# Change --train 0 to only convert and test the best-weighted model.\n",
    "# On Google colab, it doesn't print the mini-batch results, so it may appear\n",
    "# stuck for several minutes! Additionally, it is very slow compared to training\n",
    "# on a local GPU.\n",
    "\n",
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming_quantized 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "mixednet \\\n",
    "--pointwise_filters \"64,64,64,64\" \\\n",
    "--repeat_in_block  \"1, 1, 1, 1\" \\\n",
    "--mixconv_kernel_sizes '[5], [7,11], [9,15], [23]' \\\n",
    "--residual_connection \"0,0,0,0\" \\\n",
    "--first_conv_filters 32 \\\n",
    "--first_conv_kernel_size 5 \\\n",
    "--stride 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
